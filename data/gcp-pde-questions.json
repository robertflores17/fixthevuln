{
  "metadata": {
    "title": "Google Professional Data Engineer PDE Practice Questions",
    "version": "1.0",
    "total_questions": 20,
    "exam": "PDE",
    "domains": {
      "1": {
        "name": "Design Data Processing Systems",
        "weight": 20,
        "count": 4
      },
      "2": {
        "name": "Ingest and Process Data",
        "weight": 20,
        "count": 4
      },
      "3": {
        "name": "Store Data",
        "weight": 20,
        "count": 4
      },
      "4": {
        "name": "Prepare and Use Data for Analysis",
        "weight": 20,
        "count": 4
      },
      "5": {
        "name": "Maintain and Automate Data Workloads",
        "weight": 20,
        "count": 4
      }
    }
  },
  "questions": [
    {
      "id": 1,
      "domain": 1,
      "objective": "1.1",
      "difficulty": "easy",
      "question": "Which of the following is a key concept within Design Data Processing Systems (Domain 1)?",
      "options": [
        "Exactly-Once vs At-Least-Once Processing",
        "Batch vs Streaming Architecture",
        "Windowing Strategies (Fixed, Sliding, Session)",
        "Multi-Region Data Strategies"
      ],
      "correct": 0,
      "explanation": "Exactly-Once vs At-Least-Once Processing is a key concept in Design Data Processing Systems. This domain covers topics essential for the Google Professional Data Engineer exam.",
      "link": "start-here.html"
    },
    {
      "id": 2,
      "domain": 1,
      "objective": "1.2",
      "difficulty": "medium",
      "question": "A professional is tasked with design for reliability and fidelity. What should be the first step?",
      "options": [
        "Assess the current state and identify requirements",
        "Implement the solution immediately",
        "Document the findings in a report",
        "Escalate to senior management"
      ],
      "correct": 0,
      "explanation": "The first step in any design data processing systems task is to assess the current state before implementing changes.",
      "link": "start-here.html"
    },
    {
      "id": 3,
      "domain": 1,
      "objective": "1.3",
      "difficulty": "medium",
      "question": "Which concept in Design Data Processing Systems is most closely related to design for flexibility and portability?",
      "options": [
        "Design Data Processing Systems governance and oversight",
        "Design Data Processing Systems implementation and operations",
        "Design Data Processing Systems assessment and testing",
        "Design Data Processing Systems risk management"
      ],
      "correct": 1,
      "explanation": "Design for flexibility and portability falls under the implementation and operations aspect of Design Data Processing Systems.",
      "link": "start-here.html"
    },
    {
      "id": 4,
      "domain": 1,
      "objective": "1.4",
      "difficulty": "hard",
      "question": "Which of the following is a key concept within Design Data Processing Systems (Domain 1)?",
      "options": [
        "Multi-Region Data Strategies",
        "Lambda vs Kappa Architecture",
        "Data Lake vs Data Warehouse vs Lakehouse",
        "Watermarks and Late Data Handling"
      ],
      "correct": 0,
      "explanation": "Multi-Region Data Strategies is a key concept in Design Data Processing Systems. This domain covers topics essential for the Google Professional Data Engineer exam.",
      "link": "start-here.html"
    },
    {
      "id": 5,
      "domain": 2,
      "objective": "2.1",
      "difficulty": "easy",
      "question": "Which of the following is a key concept within Ingest and Process Data (Domain 2)?",
      "options": [
        "Side Inputs and Windowed Joins",
        "Dataflow Templates (Classic and Flex)",
        "Datastream for CDC",
        "Apache Beam Transforms (ParDo, GroupByKey)"
      ],
      "correct": 0,
      "explanation": "Side Inputs and Windowed Joins is a key concept in Ingest and Process Data. This domain covers topics essential for the Google Professional Data Engineer exam.",
      "link": "start-here.html"
    },
    {
      "id": 6,
      "domain": 2,
      "objective": "2.2",
      "difficulty": "medium",
      "question": "A professional is tasked with build batch and streaming data pipelines. What should be the first step?",
      "options": [
        "Assess the current state and identify requirements",
        "Implement the solution immediately",
        "Document the findings in a report",
        "Escalate to senior management"
      ],
      "correct": 0,
      "explanation": "The first step in any ingest and process data task is to assess the current state before implementing changes.",
      "link": "start-here.html"
    },
    {
      "id": 7,
      "domain": 2,
      "objective": "2.3",
      "difficulty": "medium",
      "question": "Which concept in Ingest and Process Data is most closely related to design data transformation solutions?",
      "options": [
        "Ingest and Process Data governance and oversight",
        "Ingest and Process Data implementation and operations",
        "Ingest and Process Data assessment and testing",
        "Ingest and Process Data risk management"
      ],
      "correct": 1,
      "explanation": "Design data transformation solutions falls under the implementation and operations aspect of Ingest and Process Data.",
      "link": "start-here.html"
    },
    {
      "id": 8,
      "domain": 2,
      "objective": "2.4",
      "difficulty": "hard",
      "question": "Which of the following is a key concept within Ingest and Process Data (Domain 2)?",
      "options": [
        "Datastream for CDC",
        "Dataflow Templates (Classic and Flex)",
        "Cloud Data Fusion (CDAP)",
        "Dataproc (Spark/Hadoop) Clusters"
      ],
      "correct": 0,
      "explanation": "Datastream for CDC is a key concept in Ingest and Process Data. This domain covers topics essential for the Google Professional Data Engineer exam.",
      "link": "start-here.html"
    },
    {
      "id": 9,
      "domain": 3,
      "objective": "3.1",
      "difficulty": "easy",
      "question": "Which of the following is a key concept within Store Data (Domain 3)?",
      "options": [
        "BigQuery Partitioning (Time, Range, Ingestion)",
        "Cloud Storage Classes and Lifecycle",
        "Bigtable Row Key Design",
        "Memorystore for Caching"
      ],
      "correct": 0,
      "explanation": "BigQuery Partitioning (Time, Range, Ingestion) is a key concept in Store Data. This domain covers topics essential for the Google Professional Data Engineer exam.",
      "link": "start-here.html"
    },
    {
      "id": 10,
      "domain": 3,
      "objective": "3.2",
      "difficulty": "medium",
      "question": "A professional is tasked with design schemas and data models. What should be the first step?",
      "options": [
        "Assess the current state and identify requirements",
        "Implement the solution immediately",
        "Document the findings in a report",
        "Escalate to senior management"
      ],
      "correct": 0,
      "explanation": "The first step in any store data task is to assess the current state before implementing changes.",
      "link": "start-here.html"
    },
    {
      "id": 11,
      "domain": 3,
      "objective": "3.3",
      "difficulty": "medium",
      "question": "Which concept in Store Data is most closely related to manage data storage lifecycle?",
      "options": [
        "Store Data governance and oversight",
        "Store Data implementation and operations",
        "Store Data assessment and testing",
        "Store Data risk management"
      ],
      "correct": 1,
      "explanation": "Manage data storage lifecycle falls under the implementation and operations aspect of Store Data.",
      "link": "start-here.html"
    },
    {
      "id": 12,
      "domain": 3,
      "objective": "3.1",
      "difficulty": "hard",
      "question": "Which of the following is a key concept within Store Data (Domain 3)?",
      "options": [
        "Bigtable Row Key Design",
        "Cloud Storage Classes and Lifecycle",
        "Memorystore for Caching",
        "BigQuery Clustering"
      ],
      "correct": 0,
      "explanation": "Bigtable Row Key Design is a key concept in Store Data. This domain covers topics essential for the Google Professional Data Engineer exam.",
      "link": "start-here.html"
    },
    {
      "id": 13,
      "domain": 4,
      "objective": "4.1",
      "difficulty": "easy",
      "question": "Which of the following is a key concept within Prepare and Use Data for Analysis (Domain 4)?",
      "options": [
        "BigQuery BI Engine",
        "Dataplex Data Governance",
        "Dataprep by Trifacta",
        "Analytics Hub for Data Sharing"
      ],
      "correct": 0,
      "explanation": "BigQuery BI Engine is a key concept in Prepare and Use Data for Analysis. This domain covers topics essential for the Google Professional Data Engineer exam.",
      "link": "start-here.html"
    },
    {
      "id": 14,
      "domain": 4,
      "objective": "4.2",
      "difficulty": "medium",
      "question": "A professional is tasked with share data for analysis. What should be the first step?",
      "options": [
        "Assess the current state and identify requirements",
        "Implement the solution immediately",
        "Document the findings in a report",
        "Escalate to senior management"
      ],
      "correct": 0,
      "explanation": "The first step in any prepare and use data for analysis task is to assess the current state before implementing changes.",
      "link": "start-here.html"
    },
    {
      "id": 15,
      "domain": 4,
      "objective": "4.3",
      "difficulty": "medium",
      "question": "Which concept in Prepare and Use Data for Analysis is most closely related to explore and analyze data?",
      "options": [
        "Prepare and Use Data for Analysis governance and oversight",
        "Prepare and Use Data for Analysis implementation and operations",
        "Prepare and Use Data for Analysis assessment and testing",
        "Prepare and Use Data for Analysis risk management"
      ],
      "correct": 1,
      "explanation": "Explore and analyze data falls under the implementation and operations aspect of Prepare and Use Data for Analysis.",
      "link": "start-here.html"
    },
    {
      "id": 16,
      "domain": 4,
      "objective": "4.4",
      "difficulty": "hard",
      "question": "Which of the following is a key concept within Prepare and Use Data for Analysis (Domain 4)?",
      "options": [
        "Looker and Looker Studio",
        "Data Catalog and Metadata Management",
        "Vertex AI Feature Store",
        "Connected Sheets for BigQuery"
      ],
      "correct": 0,
      "explanation": "Looker and Looker Studio is a key concept in Prepare and Use Data for Analysis. This domain covers topics essential for the Google Professional Data Engineer exam.",
      "link": "start-here.html"
    },
    {
      "id": 17,
      "domain": 5,
      "objective": "5.1",
      "difficulty": "easy",
      "question": "Which of the following is a key concept within Maintain and Automate Data Workloads (Domain 5)?",
      "options": [
        "Data Lineage and Provenance",
        "VPC Service Controls for Data",
        "Cloud Composer (Managed Airflow)",
        "BigQuery Slot Management and Reservations"
      ],
      "correct": 0,
      "explanation": "Data Lineage and Provenance is a key concept in Maintain and Automate Data Workloads. This domain covers topics essential for the Google Professional Data Engineer exam.",
      "link": "start-here.html"
    },
    {
      "id": 18,
      "domain": 5,
      "objective": "5.2",
      "difficulty": "medium",
      "question": "A professional is tasked with design and manage data governance. What should be the first step?",
      "options": [
        "Assess the current state and identify requirements",
        "Implement the solution immediately",
        "Document the findings in a report",
        "Escalate to senior management"
      ],
      "correct": 0,
      "explanation": "The first step in any maintain and automate data workloads task is to assess the current state before implementing changes.",
      "link": "start-here.html"
    },
    {
      "id": 19,
      "domain": 5,
      "objective": "5.3",
      "difficulty": "medium",
      "question": "Which concept in Maintain and Automate Data Workloads is most closely related to automate data workload management?",
      "options": [
        "Maintain and Automate Data Workloads governance and oversight",
        "Maintain and Automate Data Workloads implementation and operations",
        "Maintain and Automate Data Workloads assessment and testing",
        "Maintain and Automate Data Workloads risk management"
      ],
      "correct": 1,
      "explanation": "Automate data workload management falls under the implementation and operations aspect of Maintain and Automate Data Workloads.",
      "link": "start-here.html"
    },
    {
      "id": 20,
      "domain": 5,
      "objective": "5.4",
      "difficulty": "hard",
      "question": "Which of the following is a key concept within Maintain and Automate Data Workloads (Domain 5)?",
      "options": [
        "Data Lineage and Provenance",
        "Cloud Composer (Managed Airflow)",
        "VPC Service Controls for Data",
        "DLP API for Sensitive Data Detection"
      ],
      "correct": 0,
      "explanation": "Data Lineage and Provenance is a key concept in Maintain and Automate Data Workloads. This domain covers topics essential for the Google Professional Data Engineer exam.",
      "link": "start-here.html"
    }
  ]
}