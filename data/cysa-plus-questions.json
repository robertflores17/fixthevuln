{
  "metadata": {
    "title": "CompTIA CySA+ CS0-003 Practice Questions",
    "version": "1.0",
    "total_questions": 150,
    "exam": "CS0-003",
    "domains": {
      "1": {
        "name": "Security Operations",
        "weight": 33,
        "count": 50
      },
      "2": {
        "name": "Vulnerability Management",
        "weight": 30,
        "count": 45
      },
      "3": {
        "name": "Incident Response and Management",
        "weight": 20,
        "count": 30
      },
      "4": {
        "name": "Reporting and Communication",
        "weight": 17,
        "count": 25
      }
    }
  },
  "questions": [
    {
      "id": 1,
      "domain": 1,
      "objective": "1.1",
      "difficulty": "easy",
      "question": "What is the primary purpose of a SIEM system?",
      "options": [
        "To block malicious network traffic in real time",
        "To aggregate, correlate, and analyze security log data from multiple sources",
        "To encrypt data at rest and in transit",
        "To manage user identities and access permissions"
      ],
      "correct": 1,
      "explanation": "A SIEM (Security Information and Event Management) system collects and correlates log data from multiple sources across the environment to detect security events. It does not block traffic (that is a firewall/IPS function), encrypt data, or manage identities.",
      "link": "log-management.html"
    },
    {
      "id": 2,
      "domain": 1,
      "objective": "1.1",
      "difficulty": "easy",
      "question": "Which protocol is commonly used for centralized log collection from network devices?",
      "options": [
        "SNMP",
        "Syslog",
        "LDAP",
        "RADIUS"
      ],
      "correct": 1,
      "explanation": "Syslog (typically UDP port 514 or TCP port 514) is the standard protocol for sending log messages from network devices to a centralized log server. SNMP is for monitoring, LDAP for directory services, and RADIUS for authentication.",
      "link": "log-management.html"
    },
    {
      "id": 3,
      "domain": 1,
      "objective": "1.1",
      "difficulty": "medium",
      "question": "A security analyst notices that their SIEM is generating an excessive number of alerts for normal business traffic. What should the analyst do FIRST?",
      "options": [
        "Disable the alerting rules causing the noise",
        "Tune the correlation rules and adjust thresholds to reduce false positives",
        "Replace the SIEM with a different product",
        "Ignore the alerts and focus only on critical severity events"
      ],
      "correct": 1,
      "explanation": "The correct first step is to tune correlation rules and adjust thresholds. Disabling rules removes visibility, ignoring alerts risks missing real threats, and replacing the SIEM is premature without attempting tuning first.",
      "link": "log-management.html"
    },
    {
      "id": 4,
      "domain": 1,
      "objective": "1.2",
      "difficulty": "easy",
      "question": "What does SOAR stand for in the context of security operations?",
      "options": [
        "Security Orchestration, Automation, and Response",
        "Security Operations, Analysis, and Reporting",
        "System Optimization and Automated Recovery",
        "Secure Object Access and Retrieval"
      ],
      "correct": 0,
      "explanation": "SOAR stands for Security Orchestration, Automation, and Response. It integrates security tools and automates repetitive tasks such as incident triage, enrichment, and response actions through playbooks.",
      "link": "start-here.html"
    },
    {
      "id": 5,
      "domain": 1,
      "objective": "1.2",
      "difficulty": "medium",
      "question": "Which capability distinguishes SOAR from a traditional SIEM?",
      "options": [
        "Log aggregation from multiple sources",
        "Automated playbook-driven response actions",
        "Real-time event correlation",
        "Long-term log storage and retention"
      ],
      "correct": 1,
      "explanation": "SOAR's distinguishing feature is its ability to execute automated response playbooks that orchestrate actions across multiple security tools. Log aggregation, correlation, and storage are core SIEM capabilities.",
      "link": "start-here.html"
    },
    {
      "id": 6,
      "domain": 1,
      "objective": "1.3",
      "difficulty": "easy",
      "question": "STIX and TAXII are standards used for which purpose?",
      "options": [
        "Encrypting network communications",
        "Sharing cyber threat intelligence",
        "Performing vulnerability scanning",
        "Managing digital certificates"
      ],
      "correct": 1,
      "explanation": "STIX (Structured Threat Information Expression) defines a standardized language for representing threat intelligence, and TAXII (Trusted Automated Exchange of Intelligence Information) defines how that intelligence is transported and shared between organizations.",
      "link": "start-here.html"
    },
    {
      "id": 7,
      "domain": 1,
      "objective": "1.3",
      "difficulty": "medium",
      "question": "The MITRE ATT&CK framework categorizes adversary behavior into which of the following?",
      "options": [
        "Vulnerabilities, exploits, and patches",
        "Tactics, techniques, and procedures (TTPs)",
        "Risks, threats, and controls",
        "Confidentiality, integrity, and availability"
      ],
      "correct": 1,
      "explanation": "MITRE ATT&CK is a knowledge base of adversary tactics, techniques, and procedures (TTPs) based on real-world observations. It maps adversary behavior across the attack lifecycle from initial access through exfiltration and impact.",
      "link": "nist-framework.html"
    },
    {
      "id": 8,
      "domain": 1,
      "objective": "1.3",
      "difficulty": "medium",
      "question": "An analyst is mapping observed adversary behavior using the MITRE ATT&CK framework. The adversary used a scheduled task to maintain access after a reboot. Which tactic does this fall under?",
      "options": [
        "Execution",
        "Persistence",
        "Privilege Escalation",
        "Defense Evasion"
      ],
      "correct": 1,
      "explanation": "Creating a scheduled task to maintain access after a system reboot is a Persistence technique (T1053 - Scheduled Task/Job). While scheduled tasks can also be used for Execution and Privilege Escalation, maintaining access across reboots is specifically a Persistence objective.",
      "link": "nist-framework.html"
    },
    {
      "id": 9,
      "domain": 1,
      "objective": "1.4",
      "difficulty": "medium",
      "question": "During threat hunting, an analyst forms a hypothesis that an attacker is using DNS tunneling for data exfiltration. Which data source would be MOST useful to investigate?",
      "options": [
        "Windows Security Event Logs",
        "DNS query logs showing unusually long subdomain queries",
        "DHCP lease logs",
        "Web proxy access logs"
      ],
      "correct": 1,
      "explanation": "DNS tunneling encodes data in DNS queries, typically using unusually long subdomain names or high volumes of TXT record queries. DNS query logs would reveal these anomalous patterns. Windows event logs, DHCP logs, and proxy logs would not directly show DNS tunneling activity.",
      "link": "log-management.html"
    },
    {
      "id": 10,
      "domain": 1,
      "objective": "1.4",
      "difficulty": "hard",
      "question": "A threat hunter notices that several workstations are making DNS queries to domains with high entropy in their subdomain strings (e.g., aGVsbG8gd29ybGQ.evil.com). What attack technique does this MOST likely indicate?",
      "options": [
        "DNS cache poisoning",
        "DNS tunneling for command and control or data exfiltration",
        "DNS zone transfer attack",
        "DNS amplification DDoS"
      ],
      "correct": 1,
      "explanation": "High-entropy subdomain strings (which appear to be Base64 or hex-encoded data) are a strong indicator of DNS tunneling. Attackers encode C2 communications or exfiltrated data within DNS queries. Cache poisoning manipulates DNS responses, zone transfers copy DNS records, and amplification attacks exploit open resolvers.",
      "link": "log-management.html"
    },
    {
      "id": 11,
      "domain": 1,
      "objective": "1.1",
      "difficulty": "medium",
      "question": "Which Windows Event ID indicates a successful user logon?",
      "options": [
        "4625",
        "4624",
        "4648",
        "4672"
      ],
      "correct": 1,
      "explanation": "Windows Event ID 4624 records a successful logon. Event 4625 is a failed logon, 4648 is a logon using explicit credentials, and 4672 indicates special privileges were assigned to a new logon (admin logon).",
      "link": "log-management.html"
    },
    {
      "id": 12,
      "domain": 1,
      "objective": "1.1",
      "difficulty": "hard",
      "question": "An analyst reviewing Windows Security logs sees multiple Event ID 4625 entries with Logon Type 10 from an external IP address at 3 AM. What does this MOST likely indicate?",
      "options": [
        "A user forgot their password and is trying to log in locally",
        "A brute-force attack via Remote Desktop Protocol (RDP)",
        "A service account failing to authenticate",
        "An automated patch management process"
      ],
      "correct": 1,
      "explanation": "Event ID 4625 indicates failed logon attempts. Logon Type 10 specifically means RemoteInteractive (RDP). Multiple failed RDP logon attempts from an external IP at an unusual hour strongly suggests a brute-force attack against RDP.",
      "link": "log-management.html"
    },
    {
      "id": 13,
      "domain": 1,
      "objective": "1.5",
      "difficulty": "easy",
      "question": "What type of network monitoring captures full packet data for detailed analysis?",
      "options": [
        "NetFlow analysis",
        "Full packet capture (PCAP)",
        "SNMP polling",
        "Syslog collection"
      ],
      "correct": 1,
      "explanation": "Full packet capture (PCAP) records the complete contents of every network packet, allowing detailed forensic analysis. NetFlow captures only metadata (source/destination IP, ports, byte counts). SNMP monitors device health, and syslog collects log messages.",
      "link": "port-security.html"
    },
    {
      "id": 14,
      "domain": 1,
      "objective": "1.5",
      "difficulty": "medium",
      "question": "An analyst wants to identify which internal hosts are communicating with a known malicious IP address over the past 30 days. Which data source is MOST efficient for this analysis?",
      "options": [
        "Full packet captures from the entire 30-day period",
        "NetFlow or flow data records",
        "Firewall configuration files",
        "ARP table entries"
      ],
      "correct": 1,
      "explanation": "NetFlow data is most efficient because it records metadata about network connections (source/dest IP, ports, timestamps, byte counts) with minimal storage requirements. Full PCAP for 30 days would require enormous storage. Firewall configs show rules, not traffic. ARP tables only show current MAC-to-IP mappings.",
      "link": "port-security.html"
    },
    {
      "id": 15,
      "domain": 1,
      "objective": "1.5",
      "difficulty": "medium",
      "question": "In Wireshark, which display filter would show only HTTP GET requests?",
      "options": [
        "tcp.port == 80",
        "http.request.method == GET",
        "http contains GET",
        "ip.proto == HTTP"
      ],
      "correct": 1,
      "explanation": "The Wireshark display filter 'http.request.method == GET' specifically filters for HTTP GET requests. 'tcp.port == 80' would show all traffic on port 80 including non-HTTP. 'http contains GET' is not valid syntax. 'ip.proto == HTTP' is incorrect because ip.proto uses protocol numbers, not names.",
      "link": "port-security.html"
    },
    {
      "id": 16,
      "domain": 1,
      "objective": "1.6",
      "difficulty": "easy",
      "question": "What does EDR stand for in cybersecurity?",
      "options": [
        "Encrypted Data Recovery",
        "Endpoint Detection and Response",
        "External Defense Router",
        "Enterprise Data Replication"
      ],
      "correct": 1,
      "explanation": "EDR stands for Endpoint Detection and Response. EDR solutions monitor endpoint activities, detect suspicious behaviors, and provide response capabilities such as host isolation, process termination, and forensic data collection.",
      "link": "start-here.html"
    },
    {
      "id": 17,
      "domain": 1,
      "objective": "1.6",
      "difficulty": "medium",
      "question": "What is the key difference between EDR and XDR?",
      "options": [
        "EDR is cloud-based while XDR is on-premises only",
        "XDR extends detection and response across multiple security layers (endpoint, network, email, cloud), not just endpoints",
        "EDR uses AI while XDR uses only signature-based detection",
        "XDR replaces the need for a SIEM entirely"
      ],
      "correct": 1,
      "explanation": "XDR (Extended Detection and Response) expands beyond endpoint-only monitoring to correlate data across endpoints, network, email, cloud, and other security layers. This provides broader visibility and more context for threat detection compared to EDR's endpoint-only focus.",
      "link": "start-here.html"
    },
    {
      "id": 18,
      "domain": 1,
      "objective": "1.7",
      "difficulty": "easy",
      "question": "Which email authentication protocol uses DNS TXT records to specify which mail servers are authorized to send email for a domain?",
      "options": [
        "DKIM",
        "SPF",
        "DMARC",
        "S/MIME"
      ],
      "correct": 1,
      "explanation": "SPF (Sender Policy Framework) uses DNS TXT records to list authorized sending mail servers for a domain. DKIM uses cryptographic signatures in email headers, DMARC builds on SPF and DKIM to specify policy, and S/MIME encrypts email content.",
      "link": "encryption-cheatsheet.html"
    },
    {
      "id": 19,
      "domain": 1,
      "objective": "1.7",
      "difficulty": "medium",
      "question": "An organization wants to prevent spoofed emails from their domain and receive reports about authentication failures. Which combination should they implement?",
      "options": [
        "SPF and TLS",
        "SPF, DKIM, and DMARC",
        "S/MIME and PGP",
        "DNSSEC and DANE"
      ],
      "correct": 1,
      "explanation": "Implementing SPF, DKIM, and DMARC together provides comprehensive email authentication. SPF validates sending servers, DKIM provides cryptographic message integrity, and DMARC ties them together with a policy and reporting mechanism that sends aggregate and forensic reports.",
      "link": "encryption-cheatsheet.html"
    },
    {
      "id": 20,
      "domain": 1,
      "objective": "1.5",
      "difficulty": "medium",
      "question": "An analyst captures traffic with Wireshark and sees a TCP conversation where the client sends a SYN, receives a SYN-ACK, but never sends the final ACK. This pattern repeats hundreds of times per second. What attack is this?",
      "options": [
        "TCP session hijacking",
        "SYN flood denial-of-service attack",
        "ARP spoofing",
        "SSL stripping"
      ],
      "correct": 1,
      "explanation": "A SYN flood attack sends many SYN packets without completing the three-way handshake (never sending the final ACK). This exhausts the target's connection table by filling it with half-open connections, causing a denial of service.",
      "link": "port-security.html"
    },
    {
      "id": 21,
      "domain": 1,
      "objective": "1.1",
      "difficulty": "medium",
      "question": "Which log source would be MOST useful for detecting lateral movement within a Windows domain environment?",
      "options": [
        "Web server access logs",
        "Windows Security Event Logs showing logon events across multiple hosts",
        "DNS query logs",
        "Antivirus detection logs"
      ],
      "correct": 1,
      "explanation": "Windows Security Event Logs (especially Event IDs 4624, 4625, 4648, and 4672) across multiple hosts can reveal patterns of lateral movement such as unusual remote logons, pass-the-hash attacks, and privilege escalation across the domain.",
      "link": "log-management.html"
    },
    {
      "id": 22,
      "domain": 1,
      "objective": "1.3",
      "difficulty": "easy",
      "question": "Which type of threat intelligence is derived from publicly available sources such as news articles, social media, and government advisories?",
      "options": [
        "HUMINT",
        "OSINT",
        "SIGINT",
        "MASINT"
      ],
      "correct": 1,
      "explanation": "OSINT (Open Source Intelligence) is derived from publicly available information including news, social media, blogs, government reports, and public databases. HUMINT comes from human sources, SIGINT from signal interception, and MASINT from measurement and signature data.",
      "link": "start-here.html"
    },
    {
      "id": 23,
      "domain": 1,
      "objective": "1.4",
      "difficulty": "hard",
      "question": "A threat hunter identifies that PowerShell is being used to download and execute code from an external URL using the command 'IEX (New-Object Net.WebClient).DownloadString()'. Which MITRE ATT&CK technique is this?",
      "options": [
        "T1059.001 - Command and Scripting Interpreter: PowerShell",
        "T1047 - Windows Management Instrumentation",
        "T1218 - System Binary Proxy Execution",
        "T1055 - Process Injection"
      ],
      "correct": 0,
      "explanation": "Using PowerShell to download and execute remote code is classified under T1059.001 (Command and Scripting Interpreter: PowerShell) in the MITRE ATT&CK framework. This is a common technique for initial payload delivery and execution that leverages the built-in PowerShell interpreter.",
      "link": "nist-framework.html"
    },
    {
      "id": 24,
      "domain": 1,
      "objective": "1.2",
      "difficulty": "medium",
      "question": "In a SOAR platform, what is the purpose of a playbook?",
      "options": [
        "To document the organization's security policies",
        "To define automated step-by-step workflows for responding to specific security events",
        "To store threat intelligence indicators",
        "To generate compliance reports"
      ],
      "correct": 1,
      "explanation": "A SOAR playbook defines automated or semi-automated workflows that prescribe the steps to take when responding to specific types of security events. Playbooks orchestrate actions across multiple tools, reducing response time and ensuring consistent handling of incidents.",
      "link": "start-here.html"
    },
    {
      "id": 25,
      "domain": 1,
      "objective": "1.5",
      "difficulty": "easy",
      "question": "Which tool is widely used for capturing and analyzing network packets?",
      "options": [
        "Nessus",
        "Wireshark",
        "Burp Suite",
        "Metasploit"
      ],
      "correct": 1,
      "explanation": "Wireshark is the most widely used open-source packet analyzer for capturing and analyzing network traffic. Nessus is a vulnerability scanner, Burp Suite is a web application security tool, and Metasploit is a penetration testing framework.",
      "link": "port-security.html"
    },
    {
      "id": 26,
      "domain": 1,
      "objective": "1.6",
      "difficulty": "hard",
      "question": "An EDR agent detects that a process on a workstation is injecting code into lsass.exe. What is the MOST likely objective of this activity?",
      "options": [
        "Installing a rootkit for persistence",
        "Credential harvesting from memory",
        "Encrypting files for ransomware",
        "Establishing a reverse shell"
      ],
      "correct": 1,
      "explanation": "LSASS (Local Security Authority Subsystem Service) stores credentials in memory. Injecting into lsass.exe is a technique used by tools like Mimikatz to extract plaintext passwords, NTLM hashes, and Kerberos tickets from memory. This is a credential access technique (MITRE T1003.001).",
      "link": "start-here.html"
    },
    {
      "id": 27,
      "domain": 1,
      "objective": "1.1",
      "difficulty": "medium",
      "question": "What is the primary benefit of normalizing log data in a SIEM?",
      "options": [
        "It encrypts the log data for secure storage",
        "It converts logs from different sources into a consistent format for correlation",
        "It compresses logs to save storage space",
        "It automatically remediates detected threats"
      ],
      "correct": 1,
      "explanation": "Log normalization converts data from disparate sources (firewalls, servers, applications) into a uniform format with consistent field names and data types. This enables the SIEM to correlate events across different sources effectively.",
      "link": "log-management.html"
    },
    {
      "id": 28,
      "domain": 1,
      "objective": "1.3",
      "difficulty": "medium",
      "question": "Which level of the Traffic Light Protocol (TLP) indicates that information can be shared freely without restriction?",
      "options": [
        "TLP:RED",
        "TLP:AMBER",
        "TLP:GREEN",
        "TLP:CLEAR"
      ],
      "correct": 3,
      "explanation": "TLP:CLEAR (formerly TLP:WHITE) indicates the information carries minimal risk and can be shared freely. TLP:RED is for named recipients only, TLP:AMBER is for limited distribution within an organization, and TLP:GREEN can be shared within a community but not publicly.",
      "link": "start-here.html"
    },
    {
      "id": 29,
      "domain": 1,
      "objective": "1.4",
      "difficulty": "easy",
      "question": "What is the first step in the threat hunting process?",
      "options": [
        "Collecting all available log data",
        "Forming a hypothesis based on threat intelligence or anomalies",
        "Deploying new detection tools",
        "Writing a final report"
      ],
      "correct": 1,
      "explanation": "Threat hunting begins with forming a hypothesis about potential threats, often based on threat intelligence, known TTPs, or observed anomalies. The hunter then collects and analyzes data to confirm or refute the hypothesis.",
      "link": "start-here.html"
    },
    {
      "id": 30,
      "domain": 1,
      "objective": "1.5",
      "difficulty": "hard",
      "question": "An analyst reviewing firewall logs sees outbound connections from a server to multiple external IPs on port 443, each lasting exactly 60 seconds with identical byte counts. What does this pattern MOST likely indicate?",
      "options": [
        "Normal HTTPS web browsing",
        "C2 beaconing activity from malware",
        "TLS certificate renewal processes",
        "Load-balanced web traffic"
      ],
      "correct": 1,
      "explanation": "Regular, periodic connections with identical durations and byte counts are characteristic of command and control (C2) beaconing. Malware often communicates with C2 servers at fixed intervals. Normal browsing would show variable durations and sizes. This pattern warrants immediate investigation.",
      "link": "log-management.html"
    },
    {
      "id": 31,
      "domain": 1,
      "objective": "1.7",
      "difficulty": "medium",
      "question": "An analyst sees a spike in NXDOMAIN responses in DNS logs. What could this indicate?",
      "options": [
        "Successful DNS zone transfers",
        "A domain generation algorithm (DGA) used by malware to locate C2 servers",
        "DNS server performance optimization",
        "Successful SPF record validation"
      ],
      "correct": 1,
      "explanation": "NXDOMAIN responses indicate queries for non-existent domains. A spike in NXDOMAIN responses can indicate malware using a Domain Generation Algorithm (DGA), which generates many random domain names to find active C2 servers. Most generated domains will not resolve, causing NXDOMAIN responses.",
      "link": "log-management.html"
    },
    {
      "id": 32,
      "domain": 1,
      "objective": "1.1",
      "difficulty": "easy",
      "question": "Which of the following is a common use case for a web application firewall (WAF)?",
      "options": [
        "Encrypting database connections",
        "Blocking SQL injection and cross-site scripting attacks",
        "Managing user authentication",
        "Performing vulnerability scans"
      ],
      "correct": 1,
      "explanation": "A WAF (Web Application Firewall) inspects HTTP/HTTPS traffic and blocks common web application attacks such as SQL injection (SQLi) and cross-site scripting (XSS). It operates at Layer 7 of the OSI model and uses rules to filter malicious requests.",
      "link": "owasp-top10.html"
    },
    {
      "id": 33,
      "domain": 1,
      "objective": "1.2",
      "difficulty": "medium",
      "question": "A SOAR playbook automatically enriches an alert by querying VirusTotal, checking internal asset inventory, and looking up the user in Active Directory. This is an example of which SOAR capability?",
      "options": [
        "Orchestration",
        "Case management",
        "Threat intelligence platform",
        "Vulnerability management"
      ],
      "correct": 0,
      "explanation": "This is orchestration \u2014 the coordination of multiple tools and data sources (VirusTotal, asset inventory, AD) through an automated workflow. Orchestration connects disparate security tools to work together, which is a core SOAR capability.",
      "link": "start-here.html"
    },
    {
      "id": 34,
      "domain": 1,
      "objective": "1.6",
      "difficulty": "medium",
      "question": "Which EDR capability allows an analyst to remotely disconnect a compromised endpoint from the network while maintaining management access?",
      "options": [
        "Automated patching",
        "Host isolation (network containment)",
        "Full disk encryption",
        "Application whitelisting"
      ],
      "correct": 1,
      "explanation": "Host isolation (or network containment) is an EDR feature that disconnects the endpoint from the network to prevent lateral movement while maintaining the EDR agent's communication channel for remote investigation and remediation.",
      "link": "start-here.html"
    },
    {
      "id": 35,
      "domain": 1,
      "objective": "1.3",
      "difficulty": "medium",
      "question": "Which threat intelligence sharing standard uses JSON format to represent cyber threat information as objects and relationships?",
      "options": [
        "OpenIOC",
        "STIX 2.x",
        "YARA",
        "Snort"
      ],
      "correct": 1,
      "explanation": "STIX 2.x uses JSON to represent threat intelligence as a graph of objects (such as indicators, malware, threat actors, campaigns) and the relationships between them. OpenIOC uses XML, YARA defines malware signatures, and Snort defines network intrusion detection rules.",
      "link": "start-here.html"
    },
    {
      "id": 36,
      "domain": 1,
      "objective": "1.4",
      "difficulty": "medium",
      "question": "Which threat hunting approach starts from known indicators of compromise and searches the environment for matches?",
      "options": [
        "Hypothesis-driven hunting",
        "Intelligence-driven (IoC-based) hunting",
        "Baseline deviation analysis",
        "Machine learning anomaly detection"
      ],
      "correct": 1,
      "explanation": "Intelligence-driven or IoC-based hunting uses known indicators of compromise (IP addresses, file hashes, domain names) from threat intelligence feeds to search the environment for matches. Hypothesis-driven hunting starts from a theory about adversary behavior rather than specific indicators.",
      "link": "start-here.html"
    },
    {
      "id": 37,
      "domain": 1,
      "objective": "1.1",
      "difficulty": "medium",
      "question": "An analyst creates a SIEM correlation rule: 'Alert when more than 5 failed logon attempts (Event ID 4625) are followed by a successful logon (Event ID 4624) from the same source within 10 minutes.' What type of attack does this rule detect?",
      "options": [
        "Phishing",
        "Successful brute-force authentication attack",
        "Man-in-the-middle attack",
        "SQL injection"
      ],
      "correct": 1,
      "explanation": "This correlation rule detects a successful brute-force attack: multiple failed attempts followed by a successful logon from the same source indicates the attacker eventually guessed the correct credentials. The time window and threshold help distinguish from normal user behavior.",
      "link": "log-management.html"
    },
    {
      "id": 38,
      "domain": 1,
      "objective": "1.5",
      "difficulty": "easy",
      "question": "NetFlow data includes which of the following information?",
      "options": [
        "Full packet payload contents",
        "Source/destination IP addresses, ports, protocol, and byte counts",
        "Email message bodies and attachments",
        "File system metadata from endpoints"
      ],
      "correct": 1,
      "explanation": "NetFlow records contain metadata about network conversations: source and destination IP addresses, source and destination ports, protocol type, byte counts, packet counts, and timestamps. It does not capture actual packet payloads.",
      "link": "port-security.html"
    },
    {
      "id": 39,
      "domain": 1,
      "objective": "1.7",
      "difficulty": "hard",
      "question": "An analyst observes DNS TXT record queries to a domain at regular intervals, each containing Base64-encoded strings. The responses also contain Base64-encoded TXT records. What is MOST likely occurring?",
      "options": [
        "SPF record validation",
        "DNS tunneling for bidirectional C2 communication",
        "DKIM signature verification",
        "DNSSEC key exchange"
      ],
      "correct": 1,
      "explanation": "Regular DNS TXT queries and responses containing Base64-encoded data indicate bidirectional DNS tunneling used for C2 communication. The encoded data in queries represents commands sent to the malware, and the encoded responses carry exfiltrated data or command results back to the attacker.",
      "link": "log-management.html"
    },
    {
      "id": 40,
      "domain": 1,
      "objective": "1.6",
      "difficulty": "easy",
      "question": "What is the primary advantage of using an agent-based EDR solution compared to agentless monitoring?",
      "options": [
        "Lower cost",
        "Deeper visibility into endpoint processes, file changes, and memory activity",
        "No impact on endpoint performance",
        "Easier deployment across all operating systems"
      ],
      "correct": 1,
      "explanation": "Agent-based EDR provides deep visibility into endpoint activity including process execution, file modifications, registry changes, and memory operations. This granular telemetry enables better detection of advanced threats compared to agentless approaches that rely on network-level observation.",
      "link": "start-here.html"
    },
    {
      "id": 41,
      "domain": 1,
      "objective": "1.1",
      "difficulty": "medium",
      "question": "Which syslog severity level represents an emergency condition where the system is unusable?",
      "options": [
        "0 - Emergency",
        "1 - Alert",
        "2 - Critical",
        "3 - Error"
      ],
      "correct": 0,
      "explanation": "Syslog severity level 0 (Emergency) indicates the system is unusable. The severity levels from most to least severe are: 0-Emergency, 1-Alert, 2-Critical, 3-Error, 4-Warning, 5-Notice, 6-Informational, 7-Debug.",
      "link": "log-management.html"
    },
    {
      "id": 42,
      "domain": 1,
      "objective": "1.3",
      "difficulty": "easy",
      "question": "What is the primary purpose of an Indicator of Compromise (IoC)?",
      "options": [
        "To measure an organization's compliance posture",
        "To provide evidence that a security breach may have occurred",
        "To calculate the financial impact of a breach",
        "To assign blame for a security incident"
      ],
      "correct": 1,
      "explanation": "Indicators of Compromise (IoCs) are artifacts observed on a network or host that indicate a security breach has likely occurred. Examples include malicious IP addresses, file hashes of malware, suspicious domain names, and unusual registry modifications.",
      "link": "start-here.html"
    },
    {
      "id": 43,
      "domain": 1,
      "objective": "1.5",
      "difficulty": "hard",
      "question": "While analyzing a packet capture, an analyst notices a large number of TCP RST packets being sent from an internal server to various internal hosts on port 445. What does this MOST likely indicate?",
      "options": [
        "The server is performing normal file sharing operations",
        "An internal host is performing a port scan and the server is rejecting SMB connections",
        "The server is experiencing a DDoS attack",
        "Windows Update is distributing patches"
      ],
      "correct": 1,
      "explanation": "TCP RST packets indicate rejected connections. A pattern of RST responses on port 445 (SMB) to multiple internal hosts suggests something is attempting SMB connections that the server is refusing. This is consistent with an internal port scan or worm propagation attempting to exploit SMB vulnerabilities.",
      "link": "port-security.html"
    },
    {
      "id": 44,
      "domain": 1,
      "objective": "1.2",
      "difficulty": "easy",
      "question": "Which of the following is a benefit of using SOAR in security operations?",
      "options": [
        "It eliminates the need for security analysts entirely",
        "It reduces mean time to respond (MTTR) by automating repetitive tasks",
        "It replaces the need for firewalls and IDS",
        "It provides physical security monitoring"
      ],
      "correct": 1,
      "explanation": "SOAR reduces MTTR by automating repetitive, time-consuming tasks such as alert triage, indicator enrichment, and initial response actions. It augments analyst capabilities rather than replacing them, and does not replace network security controls.",
      "link": "start-here.html"
    },
    {
      "id": 45,
      "domain": 1,
      "objective": "1.4",
      "difficulty": "hard",
      "question": "A threat hunter analyzes process creation logs and finds cmd.exe spawning from a Microsoft Word process (winword.exe). What does this MOST likely indicate?",
      "options": [
        "A user running a legitimate macro",
        "A malicious document executing a payload via macro or exploit",
        "Microsoft Office self-updating",
        "A print spooler operation"
      ],
      "correct": 1,
      "explanation": "While legitimate macros exist, cmd.exe spawning from winword.exe is a strong indicator of a malicious document executing a payload. This is a well-known attack technique (T1204.002 - User Execution: Malicious File) where weaponized documents use macros or exploits to launch command shells for further compromise.",
      "link": "nist-framework.html"
    },
    {
      "id": 46,
      "domain": 1,
      "objective": "1.1",
      "difficulty": "medium",
      "question": "What is the purpose of log retention policies in security operations?",
      "options": [
        "To ensure logs are encrypted during transmission",
        "To define how long log data must be stored to meet operational, legal, and compliance requirements",
        "To specify which users can create log entries",
        "To determine the format of log messages"
      ],
      "correct": 1,
      "explanation": "Log retention policies define the duration for which log data must be preserved. This supports forensic investigations, regulatory compliance (such as PCI DSS requiring 1 year of log retention), legal requirements, and operational needs for trend analysis.",
      "link": "log-management.html"
    },
    {
      "id": 47,
      "domain": 1,
      "objective": "1.7",
      "difficulty": "medium",
      "question": "Which technique would BEST help detect a phishing email that passes SPF and DKIM checks but was sent from a look-alike domain?",
      "options": [
        "Implementing DMARC with strict alignment",
        "User awareness training combined with email banner warnings for external senders",
        "Increasing spam filter sensitivity",
        "Blocking all emails with attachments"
      ],
      "correct": 1,
      "explanation": "A look-alike domain (e.g., c0mpany.com vs company.com) will have its own valid SPF and DKIM records, so those checks will pass. User awareness training and external email banners help users identify suspicious look-alike domains. DMARC only validates alignment for the actual sending domain.",
      "link": "start-here.html"
    },
    {
      "id": 48,
      "domain": 1,
      "objective": "1.5",
      "difficulty": "easy",
      "question": "What is the standard port for HTTPS traffic?",
      "options": [
        "80",
        "443",
        "8080",
        "8443"
      ],
      "correct": 1,
      "explanation": "Port 443 is the standard port for HTTPS (HTTP over TLS/SSL). Port 80 is standard HTTP, port 8080 is a common alternative HTTP port, and port 8443 is a common alternative HTTPS port.",
      "link": "port-security.html"
    },
    {
      "id": 49,
      "domain": 1,
      "objective": "1.3",
      "difficulty": "medium",
      "question": "Which threat intelligence model uses a pyramid structure to show the relationship between indicators at the bottom and TTPs at the top, with increasing difficulty for adversaries to change?",
      "options": [
        "MITRE ATT&CK Matrix",
        "The Pyramid of Pain",
        "Cyber Kill Chain",
        "Diamond Model of Intrusion Analysis"
      ],
      "correct": 1,
      "explanation": "The Pyramid of Pain, created by David Bianco, illustrates that different types of indicators cause varying levels of difficulty for adversaries when defenders detect them. From bottom to top: hash values, IP addresses, domain names, network/host artifacts, tools, and TTPs (hardest to change).",
      "link": "nist-framework.html"
    },
    {
      "id": 50,
      "domain": 1,
      "objective": "1.6",
      "difficulty": "hard",
      "question": "An EDR solution detects process hollowing on a workstation, where a legitimate process (svchost.exe) has had its memory replaced with malicious code. Which MITRE ATT&CK technique does this represent?",
      "options": [
        "T1055.012 - Process Injection: Process Hollowing",
        "T1036 - Masquerading",
        "T1070 - Indicator Removal",
        "T1027 - Obfuscated Files or Information"
      ],
      "correct": 0,
      "explanation": "Process hollowing (T1055.012) is a process injection technique where an attacker creates a legitimate process in a suspended state, hollows out its memory, replaces it with malicious code, and then resumes execution. This allows malicious code to run under the guise of a trusted process.",
      "link": "nist-framework.html"
    },
    {
      "id": 51,
      "domain": 2,
      "objective": "2.1",
      "difficulty": "easy",
      "question": "What is the primary purpose of a vulnerability scanner?",
      "options": [
        "To exploit vulnerabilities and gain system access",
        "To identify known security weaknesses in systems and applications",
        "To block incoming network attacks",
        "To encrypt sensitive data at rest"
      ],
      "correct": 1,
      "explanation": "Vulnerability scanners identify known security weaknesses by comparing system configurations, software versions, and open ports against databases of known vulnerabilities. They do not exploit vulnerabilities (that is penetration testing), block attacks, or encrypt data.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 52,
      "domain": 2,
      "objective": "2.1",
      "difficulty": "easy",
      "question": "Which of the following is a widely used commercial vulnerability scanner?",
      "options": [
        "Wireshark",
        "Nessus",
        "Metasploit",
        "John the Ripper"
      ],
      "correct": 1,
      "explanation": "Nessus (by Tenable) is one of the most widely used commercial vulnerability scanners. Wireshark is a packet analyzer, Metasploit is a penetration testing framework, and John the Ripper is a password cracking tool.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 53,
      "domain": 2,
      "objective": "2.1",
      "difficulty": "medium",
      "question": "What is the key difference between a credentialed and non-credentialed vulnerability scan?",
      "options": [
        "Credentialed scans are faster",
        "Credentialed scans authenticate to the target system, providing deeper visibility into installed software, patches, and configurations",
        "Non-credentialed scans are more accurate",
        "Credentialed scans only work on Windows systems"
      ],
      "correct": 1,
      "explanation": "Credentialed (authenticated) scans log into the target system using valid credentials, allowing the scanner to examine installed software, patch levels, configurations, and local vulnerabilities. Non-credentialed scans can only assess what is visible externally and often produce more false positives.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 54,
      "domain": 2,
      "objective": "2.2",
      "difficulty": "easy",
      "question": "What does CVSS stand for?",
      "options": [
        "Common Vulnerability Scoring System",
        "Cyber Vulnerability Security Standard",
        "Critical Vulnerability Scanning Service",
        "Centralized Vulnerability Severity Score"
      ],
      "correct": 0,
      "explanation": "CVSS stands for Common Vulnerability Scoring System. It provides a standardized framework for rating the severity of security vulnerabilities on a scale of 0.0 to 10.0, helping organizations prioritize remediation efforts.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 55,
      "domain": 2,
      "objective": "2.2",
      "difficulty": "medium",
      "question": "A vulnerability has a CVSS v3.1 base score of 9.8. Which severity rating does this correspond to?",
      "options": [
        "High",
        "Critical",
        "Medium",
        "Severe"
      ],
      "correct": 1,
      "explanation": "In CVSS v3.1, scores of 9.0-10.0 are rated Critical. The severity ratings are: None (0.0), Low (0.1-3.9), Medium (4.0-6.9), High (7.0-8.9), and Critical (9.0-10.0). There is no 'Severe' rating in CVSS.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 56,
      "domain": 2,
      "objective": "2.2",
      "difficulty": "hard",
      "question": "In CVSS v3.1, which base metric combination would result in the highest possible score?",
      "options": [
        "Network attack vector, Low complexity, No privileges required, No user interaction, Changed scope, High C/I/A impact",
        "Physical attack vector, High complexity, High privileges, User interaction required, Unchanged scope, High C/I/A",
        "Adjacent attack vector, Low complexity, Low privileges, No user interaction, Unchanged scope, High C/I/A",
        "Network attack vector, High complexity, No privileges, User interaction required, Changed scope, Low C/I/A"
      ],
      "correct": 0,
      "explanation": "The highest CVSS base score (10.0) requires: Network attack vector (remotely exploitable), Low attack complexity, No privileges required, No user interaction, Changed scope (impacts resources beyond the vulnerable component), and High impact to Confidentiality, Integrity, and Availability.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 57,
      "domain": 2,
      "objective": "2.3",
      "difficulty": "easy",
      "question": "What is a CVE?",
      "options": [
        "A vulnerability scanning tool",
        "A unique identifier assigned to a publicly known security vulnerability",
        "A type of malware classification",
        "A network security protocol"
      ],
      "correct": 1,
      "explanation": "CVE (Common Vulnerabilities and Exposures) is a system that provides unique identifiers (e.g., CVE-2024-12345) for publicly known security vulnerabilities. CVE IDs are maintained by MITRE and enable consistent communication about specific vulnerabilities across tools and organizations.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 58,
      "domain": 2,
      "objective": "2.3",
      "difficulty": "medium",
      "question": "What is the difference between CVE and CWE?",
      "options": [
        "CVE identifies specific vulnerabilities; CWE categorizes types of software weaknesses",
        "CWE identifies specific vulnerabilities; CVE categorizes types of software weaknesses",
        "They are the same thing with different naming conventions",
        "CVE is for hardware vulnerabilities; CWE is for software vulnerabilities"
      ],
      "correct": 0,
      "explanation": "CVE (Common Vulnerabilities and Exposures) identifies specific vulnerability instances (e.g., CVE-2021-44228 for Log4Shell). CWE (Common Weakness Enumeration) categorizes types of software weaknesses (e.g., CWE-79 for Cross-Site Scripting). A specific CVE may be caused by a particular CWE weakness type.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 59,
      "domain": 2,
      "objective": "2.4",
      "difficulty": "medium",
      "question": "When prioritizing vulnerability remediation, which factor should be given the HIGHEST weight?",
      "options": [
        "The age of the vulnerability",
        "The criticality of the affected asset combined with the exploitability of the vulnerability",
        "The vendor who published the advisory",
        "The number of CVE references"
      ],
      "correct": 1,
      "explanation": "Remediation priority should be based on the combination of asset criticality (how important the system is to the business) and vulnerability exploitability (how easy it is to exploit, whether active exploits exist). A critical vulnerability on a non-critical system may be lower priority than a high vulnerability on a mission-critical system.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 60,
      "domain": 2,
      "objective": "2.4",
      "difficulty": "hard",
      "question": "An organization has limited patching resources. A vulnerability scan reveals: (A) CVSS 9.8 on an isolated test server with no sensitive data, (B) CVSS 7.5 on an internet-facing web server processing credit card transactions. Which should be patched FIRST?",
      "options": [
        "The test server because it has a higher CVSS score",
        "The web server because it is internet-facing, handles sensitive data, and presents greater business risk",
        "Both should be patched simultaneously",
        "Neither, as they should wait for the next maintenance window"
      ],
      "correct": 1,
      "explanation": "Despite the lower CVSS score, the internet-facing web server processing credit cards represents significantly greater business risk due to its exposure, the sensitivity of data it handles, and regulatory requirements (PCI DSS). Risk-based prioritization considers asset context, not just CVSS scores alone.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 61,
      "domain": 2,
      "objective": "2.5",
      "difficulty": "easy",
      "question": "What is the primary goal of patch management?",
      "options": [
        "To install new software features",
        "To apply updates that fix known security vulnerabilities and bugs",
        "To upgrade hardware components",
        "To monitor network traffic"
      ],
      "correct": 1,
      "explanation": "Patch management is the process of identifying, testing, and deploying software updates (patches) that fix security vulnerabilities and bugs. Effective patch management reduces the attack surface by closing known vulnerability gaps.",
      "link": "start-here.html"
    },
    {
      "id": 62,
      "domain": 2,
      "objective": "2.5",
      "difficulty": "medium",
      "question": "Before deploying a critical security patch to production servers, what should an organization do?",
      "options": [
        "Deploy immediately to all servers without testing",
        "Test the patch in a staging environment to verify compatibility and stability",
        "Wait 6 months to see if others report issues",
        "Only apply the patch if the vendor provides a warranty"
      ],
      "correct": 1,
      "explanation": "Patches should be tested in a staging environment that mirrors production before deployment. This verifies that the patch does not break existing functionality, cause compatibility issues, or introduce new problems. Emergency patches for actively exploited vulnerabilities may have accelerated testing timelines.",
      "link": "start-here.html"
    },
    {
      "id": 63,
      "domain": 2,
      "objective": "2.6",
      "difficulty": "easy",
      "question": "Which tool is specifically designed for web application vulnerability scanning and is part of the OWASP project?",
      "options": [
        "Nessus",
        "OWASP ZAP (Zed Attack Proxy)",
        "Qualys",
        "Snort"
      ],
      "correct": 1,
      "explanation": "OWASP ZAP (Zed Attack Proxy) is a free, open-source web application security scanner maintained by the OWASP Foundation. It can find vulnerabilities like SQL injection, XSS, and CSRF in web applications. Nessus and Qualys are general vulnerability scanners, and Snort is an IDS.",
      "link": "owasp-top10.html"
    },
    {
      "id": 64,
      "domain": 2,
      "objective": "2.6",
      "difficulty": "medium",
      "question": "Burp Suite is primarily used for which purpose?",
      "options": [
        "Network vulnerability scanning",
        "Web application security testing and intercepting HTTP/HTTPS traffic",
        "Operating system hardening",
        "Wireless network analysis"
      ],
      "correct": 1,
      "explanation": "Burp Suite is a web application security testing platform that acts as an intercepting proxy between the browser and the target application. It allows security testers to inspect, modify, and replay HTTP/HTTPS requests to identify vulnerabilities like SQLi, XSS, and authentication flaws.",
      "link": "owasp-top10.html"
    },
    {
      "id": 65,
      "domain": 2,
      "objective": "2.7",
      "difficulty": "medium",
      "question": "A vulnerability scanner reports that a web server is vulnerable to CVE-2017-5638 (Apache Struts RCE). Upon investigation, the analyst finds that Apache Struts is not installed on the server. What type of finding is this?",
      "options": [
        "True positive",
        "False positive",
        "True negative",
        "False negative"
      ],
      "correct": 1,
      "explanation": "This is a false positive \u2014 the scanner incorrectly reported a vulnerability that does not actually exist. The software (Apache Struts) is not even installed. False positives are common in vulnerability scanning and require analyst validation to avoid wasting remediation resources.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 66,
      "domain": 2,
      "objective": "2.7",
      "difficulty": "medium",
      "question": "Which scenario represents a false negative in vulnerability scanning?",
      "options": [
        "The scanner reports a vulnerability that actually exists",
        "The scanner reports a vulnerability on a system where the software is not installed",
        "The scanner fails to detect a vulnerability that actually exists on the target",
        "The scanner correctly reports no vulnerabilities on a fully patched system"
      ],
      "correct": 2,
      "explanation": "A false negative occurs when the scanner fails to identify a real vulnerability. This is more dangerous than a false positive because the organization remains unaware of the risk. False negatives can result from outdated scan plugins, scan misconfigurations, or vulnerabilities not yet in the scanner's database.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 67,
      "domain": 2,
      "objective": "2.1",
      "difficulty": "medium",
      "question": "Which type of vulnerability scan would have the LEAST impact on production systems?",
      "options": [
        "Authenticated scan with exploitation enabled",
        "Non-credentialed scan in discovery/passive mode",
        "Full credentialed scan during peak business hours",
        "Active scan with brute-force password testing"
      ],
      "correct": 1,
      "explanation": "A non-credentialed scan in discovery/passive mode has the least impact because it only identifies open ports and services without attempting to authenticate or actively probe for vulnerabilities. This minimizes the risk of service disruption but provides less thorough results.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 68,
      "domain": 2,
      "objective": "2.8",
      "difficulty": "easy",
      "question": "What is a vulnerability feed?",
      "options": [
        "A real-time stream of network traffic data",
        "A regularly updated database of known vulnerabilities used by scanning tools",
        "A social media account posting about security news",
        "A list of firewall rules"
      ],
      "correct": 1,
      "explanation": "A vulnerability feed is a regularly updated stream of vulnerability information (CVEs, advisories, signatures) that scanning tools use to detect known vulnerabilities. Vendors like Tenable, Qualys, and Rapid7 maintain these feeds to keep their scanners current.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 69,
      "domain": 2,
      "objective": "2.2",
      "difficulty": "medium",
      "question": "In CVSS v3.1, what does the 'Scope' metric measure?",
      "options": [
        "The geographic scope of the vulnerability",
        "Whether exploiting the vulnerability impacts resources beyond the vulnerable component's security authority",
        "The number of systems affected",
        "The time scope for remediation"
      ],
      "correct": 1,
      "explanation": "The Scope metric in CVSS v3.1 captures whether a vulnerability in one component can impact resources managed by a different security authority. 'Changed' scope means the vulnerable component impacts other components (e.g., a VM escape affecting the hypervisor), increasing the score.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 70,
      "domain": 2,
      "objective": "2.4",
      "difficulty": "medium",
      "question": "CISA maintains the Known Exploited Vulnerabilities (KEV) catalog. Why is this catalog significant for vulnerability prioritization?",
      "options": [
        "It lists all CVEs ever published",
        "It identifies vulnerabilities confirmed to be actively exploited in the wild, requiring urgent remediation",
        "It ranks vulnerabilities by CVSS score only",
        "It is a replacement for the NVD"
      ],
      "correct": 1,
      "explanation": "CISA's KEV catalog lists vulnerabilities that are confirmed to be actively exploited by threat actors. Federal agencies are required to remediate KEV entries within specified deadlines (BOD 22-01), and all organizations should prioritize these vulnerabilities as they represent real, active threats rather than theoretical risks.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 71,
      "domain": 2,
      "objective": "2.6",
      "difficulty": "medium",
      "question": "Which OWASP Top 10 (2021) category addresses flaws like SQL injection and XSS?",
      "options": [
        "A01:2021 - Broken Access Control",
        "A03:2021 - Injection",
        "A05:2021 - Security Misconfiguration",
        "A07:2021 - Identification and Authentication Failures"
      ],
      "correct": 1,
      "explanation": "A03:2021 - Injection covers vulnerabilities where untrusted data is sent to an interpreter as part of a command or query, including SQL injection, NoSQL injection, OS command injection, and Cross-Site Scripting (XSS), which was merged into this category in the 2021 edition.",
      "link": "owasp-top10.html"
    },
    {
      "id": 72,
      "domain": 2,
      "objective": "2.1",
      "difficulty": "easy",
      "question": "OpenVAS is an example of what type of security tool?",
      "options": [
        "Intrusion detection system",
        "Open-source vulnerability scanner",
        "Web application firewall",
        "Password manager"
      ],
      "correct": 1,
      "explanation": "OpenVAS (Open Vulnerability Assessment Scanner) is a free, open-source vulnerability scanner that is part of the Greenbone Vulnerability Management (GVM) framework. It can scan for thousands of known vulnerabilities across network hosts and services.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 73,
      "domain": 2,
      "objective": "2.5",
      "difficulty": "hard",
      "question": "An organization cannot patch a critical vulnerability on a production system due to application compatibility issues. Which compensating control would BEST reduce the risk?",
      "options": [
        "Documenting the risk and accepting it with no additional measures",
        "Implementing network segmentation, additional monitoring, and virtual patching via WAF or IPS rules",
        "Disabling the affected service entirely",
        "Increasing the frequency of vulnerability scans"
      ],
      "correct": 1,
      "explanation": "When patching is not feasible, compensating controls should be implemented: network segmentation limits exposure, enhanced monitoring detects exploitation attempts, and virtual patching (WAF/IPS rules) can block known exploit vectors. Simply scanning more often does not reduce risk, and disabling the service may not be business-viable.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 74,
      "domain": 2,
      "objective": "2.9",
      "difficulty": "medium",
      "question": "What is risk scoring in the context of vulnerability management?",
      "options": [
        "Assigning random priority numbers to vulnerabilities",
        "Combining vulnerability severity with asset context, threat intelligence, and business impact to determine remediation priority",
        "Using only CVSS scores to rank all vulnerabilities",
        "Counting the total number of vulnerabilities per system"
      ],
      "correct": 1,
      "explanation": "Risk scoring goes beyond CVSS by incorporating asset criticality, business context, threat intelligence (is it being actively exploited?), and environmental factors to produce a prioritized score that reflects actual organizational risk, not just technical severity.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 75,
      "domain": 2,
      "objective": "2.6",
      "difficulty": "medium",
      "question": "During a web application scan, OWASP ZAP discovers that the application reflects user input in the HTTP response without encoding. Which vulnerability does this indicate?",
      "options": [
        "SQL injection",
        "Reflected Cross-Site Scripting (XSS)",
        "Server-Side Request Forgery (SSRF)",
        "XML External Entity (XXE) injection"
      ],
      "correct": 1,
      "explanation": "When user input is reflected back in the HTTP response without proper output encoding, it creates a Reflected XSS vulnerability. An attacker can craft a URL containing malicious JavaScript that executes in the victim's browser when they click the link. Proper output encoding prevents this by escaping special characters.",
      "link": "owasp-top10.html"
    },
    {
      "id": 76,
      "domain": 2,
      "objective": "2.1",
      "difficulty": "medium",
      "question": "What is the advantage of running vulnerability scans from both internal and external perspectives?",
      "options": [
        "It doubles the number of findings for better metrics",
        "Internal scans find vulnerabilities visible within the network while external scans reveal what attackers can see from the internet, providing comprehensive coverage",
        "External scans are more accurate than internal scans",
        "Internal scans do not require credentials"
      ],
      "correct": 1,
      "explanation": "Internal and external scans provide different perspectives. External scans show the attack surface visible from the internet (what an external attacker sees), while internal scans identify vulnerabilities accessible from within the network (relevant for insider threats and post-breach scenarios). Both views are needed for comprehensive vulnerability assessment.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 77,
      "domain": 2,
      "objective": "2.3",
      "difficulty": "easy",
      "question": "The National Vulnerability Database (NVD) is maintained by which organization?",
      "options": [
        "MITRE",
        "NIST",
        "CISA",
        "OWASP"
      ],
      "correct": 1,
      "explanation": "The National Vulnerability Database (NVD) is maintained by NIST (National Institute of Standards and Technology). It provides enhanced CVE data including CVSS scores, CWE classifications, and affected product information. MITRE maintains the CVE list itself, while NVD adds analysis.",
      "link": "nist-framework.html"
    },
    {
      "id": 78,
      "domain": 2,
      "objective": "2.4",
      "difficulty": "medium",
      "question": "Which metric indicates the average time between a vulnerability being discovered and a patch being applied?",
      "options": [
        "Mean Time to Detect (MTTD)",
        "Mean Time to Remediate (MTTR)",
        "Mean Time Between Failures (MTBF)",
        "Mean Time to Acknowledge (MTTA)"
      ],
      "correct": 1,
      "explanation": "Mean Time to Remediate (MTTR) measures the average time from vulnerability discovery to successful patch application or remediation. This metric helps organizations track the efficiency of their vulnerability management program and identify areas for improvement.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 79,
      "domain": 2,
      "objective": "2.7",
      "difficulty": "medium",
      "question": "An analyst reviewing vulnerability scan results notices that 30% of findings are false positives. What is the BEST approach to reduce false positives in future scans?",
      "options": [
        "Delete the false positive results from the report",
        "Use credentialed scans, update scan plugins, and configure scan policies to match the environment",
        "Stop scanning and rely on vendor advisories only",
        "Reduce the scan scope to only critical assets"
      ],
      "correct": 1,
      "explanation": "False positives can be reduced by using credentialed scans (which verify actual software versions), keeping scan plugins updated, and configuring scan policies appropriate to the environment. Credentialed scans have direct system access and produce significantly fewer false positives than non-credentialed scans.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 80,
      "domain": 2,
      "objective": "2.5",
      "difficulty": "easy",
      "question": "Which term describes a vulnerability that is being exploited before a patch is available?",
      "options": [
        "Backdoor",
        "Zero-day vulnerability",
        "Logic bomb",
        "Buffer overflow"
      ],
      "correct": 1,
      "explanation": "A zero-day vulnerability is one that is exploited before the vendor is aware of it or has released a patch. The term 'zero-day' refers to the fact that the vendor has had zero days to fix it. These are particularly dangerous because no patch exists at the time of exploitation.",
      "link": "start-here.html"
    },
    {
      "id": 81,
      "domain": 2,
      "objective": "2.2",
      "difficulty": "hard",
      "question": "A vulnerability has the following CVSS v3.1 vector: AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H. What is the base score?",
      "options": [
        "7.5",
        "8.8",
        "9.8",
        "10.0"
      ],
      "correct": 2,
      "explanation": "This vector describes a network-exploitable vulnerability with low complexity, no privileges required, no user interaction, unchanged scope, and high impact to confidentiality, integrity, and availability. This yields a CVSS base score of 9.8. It would be 10.0 only if the scope were Changed (S:C).",
      "link": "cvss-calculator.html"
    },
    {
      "id": 82,
      "domain": 2,
      "objective": "2.6",
      "difficulty": "easy",
      "question": "Which vulnerability allows an attacker to execute arbitrary SQL commands against a database through user input fields?",
      "options": [
        "Cross-Site Scripting (XSS)",
        "SQL Injection",
        "Directory Traversal",
        "Cross-Site Request Forgery (CSRF)"
      ],
      "correct": 1,
      "explanation": "SQL injection occurs when an attacker inserts malicious SQL statements into input fields that are passed to a database query without proper sanitization. This can allow data extraction, modification, deletion, or even command execution on the database server.",
      "link": "owasp-top10.html"
    },
    {
      "id": 83,
      "domain": 2,
      "objective": "2.9",
      "difficulty": "hard",
      "question": "An organization uses EPSS (Exploit Prediction Scoring System) alongside CVSS for vulnerability prioritization. What does EPSS provide that CVSS alone does not?",
      "options": [
        "A severity rating based on technical impact",
        "A probability estimate of a vulnerability being exploited in the wild within the next 30 days",
        "A list of affected software versions",
        "A compliance mapping to regulatory frameworks"
      ],
      "correct": 1,
      "explanation": "EPSS (Exploit Prediction Scoring System) provides a probability score (0 to 1) estimating the likelihood that a vulnerability will be exploited in the wild within the next 30 days. This complements CVSS (which measures severity) by adding threat likelihood, enabling more effective risk-based prioritization.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 84,
      "domain": 2,
      "objective": "2.1",
      "difficulty": "medium",
      "question": "Which Qualys feature allows continuous monitoring of the network for new assets and vulnerabilities rather than scheduled point-in-time scans?",
      "options": [
        "Qualys WAS",
        "Qualys VMDR with continuous monitoring agents",
        "Qualys SSL Labs",
        "Qualys PCI Compliance"
      ],
      "correct": 1,
      "explanation": "Qualys VMDR (Vulnerability Management, Detection, and Response) supports continuous monitoring through cloud agents installed on endpoints. These agents provide real-time visibility into vulnerabilities without relying solely on scheduled network scans, enabling faster detection of new vulnerabilities.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 85,
      "domain": 2,
      "objective": "2.4",
      "difficulty": "medium",
      "question": "When categorizing remediation actions, what is the difference between a fix, a mitigation, and an acceptance?",
      "options": [
        "They are all the same thing",
        "A fix eliminates the vulnerability, a mitigation reduces the risk without fully eliminating it, and acceptance acknowledges the risk without action",
        "A fix is temporary, a mitigation is permanent, and acceptance requires approval",
        "Only fixes are valid remediation strategies"
      ],
      "correct": 1,
      "explanation": "A fix (remediation) completely eliminates the vulnerability (e.g., applying a patch). A mitigation reduces the risk to an acceptable level without fully eliminating the vulnerability (e.g., compensating controls). Risk acceptance means the organization formally acknowledges and accepts the remaining risk without additional action.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 86,
      "domain": 2,
      "objective": "2.6",
      "difficulty": "medium",
      "question": "What is the purpose of a dynamic application security test (DAST)?",
      "options": [
        "To review source code for security flaws",
        "To test a running web application for vulnerabilities by sending crafted requests",
        "To scan container images for known CVEs",
        "To perform static analysis of binaries"
      ],
      "correct": 1,
      "explanation": "DAST (Dynamic Application Security Testing) tests a running application from the outside by sending crafted HTTP requests and analyzing responses. It simulates an attacker's perspective and can find runtime vulnerabilities like injection flaws, authentication issues, and misconfigurations. SAST reviews source code, which is a different approach.",
      "link": "owasp-top10.html"
    },
    {
      "id": 87,
      "domain": 2,
      "objective": "2.3",
      "difficulty": "hard",
      "question": "CVE-2021-44228 (Log4Shell) received a CVSS score of 10.0. Which characteristics of this vulnerability justify the maximum score?",
      "options": [
        "It only affects legacy systems and requires physical access",
        "It allows unauthenticated remote code execution via a simple string in log messages, with network attack vector, low complexity, no privileges, no user interaction, and changed scope",
        "It requires a valid user account and local access to exploit",
        "It only causes a denial of service with no data impact"
      ],
      "correct": 1,
      "explanation": "Log4Shell (CVE-2021-44228) scored 10.0 because it could be exploited remotely with no authentication, low complexity (simply sending a crafted JNDI lookup string in any logged input), required no user interaction, had changed scope (could impact the underlying server), and resulted in full remote code execution (high C/I/A impact).",
      "link": "cvss-calculator.html"
    },
    {
      "id": 88,
      "domain": 2,
      "objective": "2.5",
      "difficulty": "medium",
      "question": "Which patch management best practice helps ensure patches do not cause outages?",
      "options": [
        "Applying all patches immediately to production without testing",
        "Maintaining a test environment that mirrors production and validating patches before deployment",
        "Only applying patches once per year",
        "Relying on the vendor's testing alone"
      ],
      "correct": 1,
      "explanation": "Maintaining a staging/test environment that mirrors the production configuration allows organizations to validate that patches do not break applications or cause compatibility issues before rolling them out. This is a fundamental patch management best practice that balances security urgency with operational stability.",
      "link": "start-here.html"
    },
    {
      "id": 89,
      "domain": 2,
      "objective": "2.7",
      "difficulty": "easy",
      "question": "What should an analyst do after confirming that a vulnerability scan finding is a true positive?",
      "options": [
        "Delete the finding from the report",
        "Document the finding and initiate the remediation process according to its risk priority",
        "Immediately shut down the affected system",
        "Rerun the scan to triple-check"
      ],
      "correct": 1,
      "explanation": "After confirming a true positive, the analyst should document the finding, assess its risk level based on asset criticality and vulnerability severity, and initiate remediation according to the organization's vulnerability management process and SLAs for the given risk level.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 90,
      "domain": 2,
      "objective": "2.8",
      "difficulty": "medium",
      "question": "How frequently should vulnerability scanner plugins and feeds be updated?",
      "options": [
        "Once per year during the annual audit",
        "As frequently as possible, ideally daily or whenever new updates are released",
        "Only when a major vulnerability is announced",
        "Monthly at the same time as patch Tuesday"
      ],
      "correct": 1,
      "explanation": "Vulnerability scanner plugins and feeds should be updated as frequently as possible, ideally daily. New vulnerabilities are discovered constantly, and outdated plugins will miss newly disclosed CVEs. Most enterprise scanners support automatic daily plugin updates.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 91,
      "domain": 2,
      "objective": "2.1",
      "difficulty": "hard",
      "question": "An analyst needs to scan a cloud environment (AWS). Which consideration is unique to cloud vulnerability scanning compared to traditional on-premises scanning?",
      "options": [
        "Cloud systems cannot be scanned at all",
        "Cloud scanning must account for shared responsibility model, API-based asset discovery, ephemeral resources, and cloud provider scanning policies",
        "Cloud systems only need external scans",
        "CVSS scores do not apply to cloud vulnerabilities"
      ],
      "correct": 1,
      "explanation": "Cloud vulnerability scanning must consider the shared responsibility model (the provider secures infrastructure while the customer secures configurations and applications), use cloud-native APIs for asset discovery, handle ephemeral/auto-scaling resources, and comply with the cloud provider's acceptable use policies for scanning.",
      "link": "cloud-security.html"
    },
    {
      "id": 92,
      "domain": 2,
      "objective": "2.9",
      "difficulty": "medium",
      "question": "What is the purpose of a vulnerability exception (risk acceptance) process?",
      "options": [
        "To permanently ignore all vulnerabilities below a certain score",
        "To formally document and obtain management approval when a vulnerability cannot be remediated within SLA and the residual risk is accepted",
        "To delete vulnerabilities from the tracking system",
        "To blame the vendor for not releasing a patch"
      ],
      "correct": 1,
      "explanation": "A vulnerability exception process provides a formal mechanism for documenting why a vulnerability cannot be remediated within the standard SLA, what compensating controls are in place, and obtaining management approval for accepting the residual risk. Exceptions should be time-limited and reviewed periodically.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 93,
      "domain": 2,
      "objective": "2.6",
      "difficulty": "hard",
      "question": "A web application scanner identifies that a site is vulnerable to Server-Side Request Forgery (SSRF). What risk does this vulnerability present?",
      "options": [
        "Attackers can forge the server's SSL certificate",
        "Attackers can make the server send requests to internal resources, potentially accessing metadata services, internal APIs, or other backend systems",
        "Attackers can inject JavaScript into other users' browsers",
        "Attackers can bypass client-side form validation"
      ],
      "correct": 1,
      "explanation": "SSRF allows an attacker to make the vulnerable server send HTTP requests to arbitrary destinations, including internal resources not accessible from the internet. In cloud environments, this is especially dangerous as it can access instance metadata services (like AWS IMDSv1 at 169.254.169.254) to obtain credentials.",
      "link": "owasp-top10.html"
    },
    {
      "id": 94,
      "domain": 2,
      "objective": "2.2",
      "difficulty": "easy",
      "question": "What is the CVSS v3.1 severity rating for a vulnerability with a base score of 5.5?",
      "options": [
        "Low",
        "Medium",
        "High",
        "Critical"
      ],
      "correct": 1,
      "explanation": "In CVSS v3.1, a base score of 5.5 falls in the Medium severity range (4.0-6.9). The severity ratings are: None (0.0), Low (0.1-3.9), Medium (4.0-6.9), High (7.0-8.9), and Critical (9.0-10.0).",
      "link": "cvss-calculator.html"
    },
    {
      "id": 95,
      "domain": 2,
      "objective": "2.4",
      "difficulty": "hard",
      "question": "An organization implements a Service Level Agreement (SLA) requiring Critical vulnerabilities to be remediated within 15 days, High within 30 days, Medium within 90 days, and Low within 180 days. A scan reveals a Critical vulnerability on a system that cannot be patched for 60 days due to vendor constraints. What is the BEST course of action?",
      "options": [
        "Ignore the SLA since the vendor has not released a patch",
        "Submit a formal risk exception with compensating controls, obtain management approval, and document a remediation plan for when the patch becomes available",
        "Reclassify the vulnerability as Low to meet the SLA",
        "Remove the system from future scans"
      ],
      "correct": 1,
      "explanation": "When a vulnerability cannot be remediated within SLA due to legitimate constraints, the proper course is to submit a formal risk exception documenting the reason, implement compensating controls to reduce risk, obtain management approval for the extended timeline, and create a remediation plan. Reclassifying or hiding the vulnerability is unethical and increases risk.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 96,
      "domain": 3,
      "objective": "3.1",
      "difficulty": "easy",
      "question": "According to NIST SP 800-61, what are the four phases of the incident response lifecycle?",
      "options": [
        "Identify, Protect, Detect, Respond",
        "Preparation; Detection and Analysis; Containment, Eradication, and Recovery; Post-Incident Activity",
        "Plan, Do, Check, Act",
        "Prevent, Detect, Respond, Recover"
      ],
      "correct": 1,
      "explanation": "NIST SP 800-61 (Computer Security Incident Handling Guide) defines four phases: (1) Preparation, (2) Detection and Analysis, (3) Containment, Eradication, and Recovery, and (4) Post-Incident Activity (lessons learned). This is the most widely referenced incident response framework.",
      "link": "incident-response.html"
    },
    {
      "id": 97,
      "domain": 3,
      "objective": "3.1",
      "difficulty": "easy",
      "question": "Which phase of incident response focuses on building capabilities BEFORE an incident occurs?",
      "options": [
        "Detection and Analysis",
        "Preparation",
        "Containment",
        "Recovery"
      ],
      "correct": 1,
      "explanation": "The Preparation phase involves establishing incident response capabilities before incidents occur. This includes creating IR plans and playbooks, building the IR team, deploying tools, conducting training and exercises, and establishing communication procedures.",
      "link": "incident-response.html"
    },
    {
      "id": 98,
      "domain": 3,
      "objective": "3.2",
      "difficulty": "medium",
      "question": "During incident containment, an analyst needs to isolate a compromised server. Which containment strategy preserves the MOST forensic evidence?",
      "options": [
        "Immediately power off the server",
        "Disconnect the server from the network while keeping it running to preserve volatile memory data",
        "Reinstall the operating system",
        "Delete all suspicious files"
      ],
      "correct": 1,
      "explanation": "Disconnecting the network while keeping the system running preserves volatile data in memory (running processes, network connections, loaded modules) that would be lost on shutdown. A memory capture should be taken before any other actions. Powering off destroys volatile evidence, and reinstalling or deleting files destroys disk evidence.",
      "link": "incident-response.html"
    },
    {
      "id": 99,
      "domain": 3,
      "objective": "3.2",
      "difficulty": "medium",
      "question": "What is the correct order of volatility for digital evidence collection?",
      "options": [
        "Hard drive, network traffic, memory, swap space",
        "CPU registers/cache, memory (RAM), network state, running processes, disk, remote logging, physical configuration",
        "Physical media, cloud storage, backups, emails",
        "Application logs, database records, configuration files, source code"
      ],
      "correct": 1,
      "explanation": "The order of volatility (RFC 3227) prioritizes collecting the most volatile evidence first: CPU registers/cache, then RAM, network state, running processes, disk storage, remote logging data, and finally physical configuration/topology. Memory evidence disappears in seconds while disk evidence persists.",
      "link": "incident-response.html"
    },
    {
      "id": 100,
      "domain": 3,
      "objective": "3.3",
      "difficulty": "easy",
      "question": "What is the purpose of maintaining chain of custody during a forensic investigation?",
      "options": [
        "To encrypt evidence for secure storage",
        "To document every person who handled the evidence and every transfer, ensuring its integrity and admissibility",
        "To speed up the investigation process",
        "To determine the financial cost of the incident"
      ],
      "correct": 1,
      "explanation": "Chain of custody is a documented chronological record of who collected, handled, transferred, and stored digital evidence. It ensures evidence integrity and is critical for legal admissibility. Any break in the chain can render evidence inadmissible in court.",
      "link": "incident-response.html"
    },
    {
      "id": 101,
      "domain": 3,
      "objective": "3.3",
      "difficulty": "medium",
      "question": "When creating a forensic copy of a hard drive, which tool creates a bit-for-bit image and what should be used to verify its integrity?",
      "options": [
        "xcopy to copy files and antivirus to verify",
        "dd or FTK Imager to create the image and cryptographic hash (MD5/SHA-256) to verify integrity",
        "Windows Backup to create the image and file count to verify",
        "Ghost imaging and visual inspection"
      ],
      "correct": 1,
      "explanation": "Forensic imaging tools like dd or FTK Imager create bit-for-bit copies including slack space, deleted files, and unallocated space. A cryptographic hash (SHA-256 preferred, MD5 acceptable) of both the source and the image is computed and compared to verify the copy is identical and has not been altered.",
      "link": "incident-response.html"
    },
    {
      "id": 102,
      "domain": 3,
      "objective": "3.4",
      "difficulty": "medium",
      "question": "Which type of malware analysis examines code behavior by running it in a controlled environment?",
      "options": [
        "Static analysis",
        "Dynamic analysis (behavioral analysis)",
        "Signature analysis",
        "Heuristic analysis"
      ],
      "correct": 1,
      "explanation": "Dynamic analysis (behavioral analysis) involves executing malware in a controlled environment (sandbox) to observe its behavior: what files it creates/modifies, network connections it makes, registry changes, and processes it spawns. Static analysis examines code without executing it.",
      "link": "incident-response.html"
    },
    {
      "id": 103,
      "domain": 3,
      "objective": "3.4",
      "difficulty": "hard",
      "question": "An analyst performs static analysis on a suspicious executable and finds strings containing 'cmd.exe /c', Base64-encoded PowerShell commands, and references to 'HKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\Run'. What can be inferred?",
      "options": [
        "The file is a legitimate system utility",
        "The malware likely executes commands via cmd.exe, uses encoded PowerShell for obfuscation, and establishes persistence via the Run registry key",
        "The file is a PDF document",
        "The malware only affects Linux systems"
      ],
      "correct": 1,
      "explanation": "The strings indicate: cmd.exe /c is used for command execution, Base64-encoded PowerShell suggests obfuscated payload delivery, and the Run registry key (HKLM\\...\\CurrentVersion\\Run) is a common persistence mechanism that executes programs at startup. Together these indicate a malware dropper or RAT establishing persistence.",
      "link": "incident-response.html"
    },
    {
      "id": 104,
      "domain": 3,
      "objective": "3.5",
      "difficulty": "easy",
      "question": "Which of the following is an example of an Indicator of Compromise (IoC)?",
      "options": [
        "A security policy document",
        "A known malicious file hash (e.g., SHA-256 of malware)",
        "A network diagram",
        "A user training completion certificate"
      ],
      "correct": 1,
      "explanation": "A known malicious file hash is an IoC because it provides concrete evidence that can be used to detect the presence of specific malware on a system. Other common IoCs include malicious IP addresses, domain names, URLs, registry modifications, and unusual file paths.",
      "link": "incident-response.html"
    },
    {
      "id": 105,
      "domain": 3,
      "objective": "3.5",
      "difficulty": "medium",
      "question": "An analyst identifies the following IoCs on a compromised system: new scheduled task running at startup, outbound connections to an IP in a known threat feed, and a new local admin account. What phase of the attack lifecycle is the adversary in?",
      "options": [
        "Initial Access only",
        "Post-exploitation: the adversary has established persistence, command and control, and privilege escalation",
        "Reconnaissance only",
        "The system has not been compromised"
      ],
      "correct": 1,
      "explanation": "The combination of a scheduled task (persistence), outbound C2 connections (command and control), and a new local admin account (privilege escalation) indicates the adversary is in the post-exploitation phase and has established a strong foothold in the environment. Immediate containment is required.",
      "link": "incident-response.html"
    },
    {
      "id": 106,
      "domain": 3,
      "objective": "3.6",
      "difficulty": "easy",
      "question": "What is a security incident response playbook?",
      "options": [
        "A list of all security tools in the organization",
        "A predefined set of procedures for responding to a specific type of security incident",
        "A log file containing all security events",
        "A training manual for new employees"
      ],
      "correct": 1,
      "explanation": "An incident response playbook is a documented set of step-by-step procedures for detecting, analyzing, containing, eradicating, and recovering from a specific type of security incident (e.g., ransomware playbook, phishing playbook, data breach playbook). Playbooks ensure consistent and efficient response.",
      "link": "incident-response.html"
    },
    {
      "id": 107,
      "domain": 3,
      "objective": "3.6",
      "difficulty": "medium",
      "question": "A ransomware playbook should include which critical first step after detection?",
      "options": [
        "Pay the ransom immediately",
        "Isolate affected systems from the network to prevent further encryption and lateral movement",
        "Format all affected drives",
        "Contact the media"
      ],
      "correct": 1,
      "explanation": "The critical first step after detecting ransomware is to isolate affected systems from the network. This prevents the ransomware from spreading to additional systems, encrypting network shares, and communicating with C2 servers. Paying the ransom is discouraged as it funds criminal activity and does not guarantee recovery.",
      "link": "incident-response.html"
    },
    {
      "id": 108,
      "domain": 3,
      "objective": "3.7",
      "difficulty": "medium",
      "question": "During a security incident, who should be responsible for communicating with external parties such as law enforcement and regulatory bodies?",
      "options": [
        "Any SOC analyst who discovers the incident",
        "Designated incident commander or management, coordinating with legal counsel and public relations",
        "The IT help desk",
        "The system administrator of the affected server"
      ],
      "correct": 1,
      "explanation": "External communications during incidents should be handled by designated personnel (incident commander, CISO, or management) in coordination with legal counsel and PR. Unauthorized external communication can create legal liability, damage the investigation, or cause unnecessary reputational harm.",
      "link": "incident-response.html"
    },
    {
      "id": 109,
      "domain": 3,
      "objective": "3.8",
      "difficulty": "easy",
      "question": "What is the purpose of a lessons learned session after an incident?",
      "options": [
        "To assign blame to individuals who made mistakes",
        "To review what happened, what worked, what failed, and how to improve the incident response process",
        "To delete all evidence of the incident",
        "To calculate overtime pay for the response team"
      ],
      "correct": 1,
      "explanation": "A lessons learned (post-incident review or after-action report) session reviews the incident timeline, evaluates the effectiveness of the response, identifies gaps in processes or tools, and produces actionable recommendations for improvement. It should be blameless and focused on systemic improvements.",
      "link": "incident-response.html"
    },
    {
      "id": 110,
      "domain": 3,
      "objective": "3.2",
      "difficulty": "hard",
      "question": "During the eradication phase of incident response, the team removes malware from infected systems. However, one week later, the same malware reappears. What is the MOST likely cause?",
      "options": [
        "The antivirus signatures are outdated",
        "The persistence mechanism was not fully identified and removed, or the initial attack vector was not closed",
        "The malware mutated on its own",
        "A different threat actor launched a new attack"
      ],
      "correct": 1,
      "explanation": "Malware reappearing after eradication typically means the persistence mechanism (registry keys, scheduled tasks, services, bootkits) was not fully removed, or the initial attack vector (e.g., unpatched vulnerability, compromised credentials) was not addressed, allowing re-infection. Thorough eradication requires identifying all persistence mechanisms and closing the initial entry point.",
      "link": "incident-response.html"
    },
    {
      "id": 111,
      "domain": 3,
      "objective": "3.3",
      "difficulty": "hard",
      "question": "A forensic analyst needs to examine a disk image for evidence of data exfiltration. Which artifacts would be MOST relevant?",
      "options": [
        "Desktop wallpaper settings and font preferences",
        "Browser history, USB device connection logs, recently accessed files, and command history",
        "Printer configuration and display settings",
        "Application installation dates only"
      ],
      "correct": 1,
      "explanation": "To investigate data exfiltration, the analyst should examine: browser history (cloud uploads, webmail), USB device logs (USBSTOR registry key showing connected devices), recently accessed files (LNK files, jump lists), command history (PowerShell, cmd), and network connection artifacts. These collectively reveal what data was accessed and how it was moved.",
      "link": "incident-response.html"
    },
    {
      "id": 112,
      "domain": 3,
      "objective": "3.1",
      "difficulty": "medium",
      "question": "Which document should define the roles, responsibilities, and escalation procedures for the incident response team?",
      "options": [
        "The acceptable use policy",
        "The incident response plan (IRP)",
        "The disaster recovery plan",
        "The data classification policy"
      ],
      "correct": 1,
      "explanation": "The Incident Response Plan (IRP) defines the IR team structure, individual roles and responsibilities, escalation procedures, communication channels, and the overall framework for handling security incidents. It is the foundational document created during the Preparation phase.",
      "link": "incident-response.html"
    },
    {
      "id": 113,
      "domain": 3,
      "objective": "3.4",
      "difficulty": "medium",
      "question": "What is the advantage of detonating suspicious files in a sandbox rather than on a production system?",
      "options": [
        "Sandboxes provide faster analysis than production systems",
        "Sandboxes provide an isolated environment where malware can execute without risk to production systems while behavior is monitored",
        "Sandboxes automatically generate patches for detected malware",
        "Sandboxes can only analyze known malware"
      ],
      "correct": 1,
      "explanation": "A sandbox provides an isolated, instrumented environment where suspicious files can be safely executed (detonated) to observe their behavior without risking production systems. The sandbox monitors process creation, file system changes, network activity, and registry modifications to characterize the malware.",
      "link": "incident-response.html"
    },
    {
      "id": 114,
      "domain": 3,
      "objective": "3.2",
      "difficulty": "easy",
      "question": "What is the primary goal of the containment phase in incident response?",
      "options": [
        "To identify who caused the incident",
        "To limit the scope and impact of the incident and prevent further damage",
        "To restore all systems to normal operations",
        "To write the final incident report"
      ],
      "correct": 1,
      "explanation": "Containment aims to limit the scope and impact of an incident by preventing it from spreading. This may involve isolating affected systems, blocking malicious IPs/domains, disabling compromised accounts, or implementing additional network segmentation. The goal is to stop the bleeding before eradication.",
      "link": "incident-response.html"
    },
    {
      "id": 115,
      "domain": 3,
      "objective": "3.5",
      "difficulty": "hard",
      "question": "An analyst discovers that an attacker used a legitimate remote access tool (AnyDesk) for lateral movement. Why does this make detection more challenging?",
      "options": [
        "AnyDesk uses strong encryption that cannot be inspected",
        "Living-off-the-land techniques using legitimate tools blend in with normal activity and bypass signature-based detection",
        "AnyDesk cannot be monitored by EDR solutions",
        "Legitimate tools do not generate log entries"
      ],
      "correct": 1,
      "explanation": "When attackers use legitimate tools (living off the land), their activity blends with normal administrative operations. Signature-based detection cannot flag authorized software as malicious. Detection requires behavioral analysis: unusual times, unusual users, unusual target systems, or unusual data volumes associated with the legitimate tool's usage.",
      "link": "incident-response.html"
    },
    {
      "id": 116,
      "domain": 3,
      "objective": "3.7",
      "difficulty": "medium",
      "question": "During a data breach involving personally identifiable information (PII), what legal obligation does the organization MOST likely have?",
      "options": [
        "No obligation unless financial data is involved",
        "Notification to affected individuals and potentially regulatory authorities within required timeframes",
        "Only internal reporting to the IT department",
        "Obligation to pay all affected individuals immediately"
      ],
      "correct": 1,
      "explanation": "Most data breach notification laws (such as state breach notification laws, GDPR Article 33/34, HIPAA) require organizations to notify affected individuals and regulatory authorities within specified timeframes when PII is compromised. GDPR requires notification within 72 hours. Failure to notify can result in significant fines.",
      "link": "incident-response.html"
    },
    {
      "id": 117,
      "domain": 3,
      "objective": "3.2",
      "difficulty": "medium",
      "question": "After containing a malware incident, the eradication phase should include which of the following actions?",
      "options": [
        "Restoring systems from the most recent backup immediately",
        "Removing malware, closing the attack vector, resetting compromised credentials, and patching exploited vulnerabilities",
        "Purchasing new hardware to replace infected systems",
        "Updating the company website with incident details"
      ],
      "correct": 1,
      "explanation": "Eradication involves removing all traces of the threat: deleting malware, removing persistence mechanisms, patching the vulnerability that was exploited, resetting all potentially compromised credentials, and verifying that the attack vector is closed. Only after thorough eradication should recovery begin.",
      "link": "incident-response.html"
    },
    {
      "id": 118,
      "domain": 3,
      "objective": "3.8",
      "difficulty": "medium",
      "question": "Which artifact should be produced as part of the post-incident activity phase?",
      "options": [
        "A marketing press release",
        "An after-action report documenting the incident timeline, response actions, findings, and improvement recommendations",
        "A list of employees to terminate",
        "A purchase order for new security tools"
      ],
      "correct": 1,
      "explanation": "The after-action report (AAR) or post-incident report is the key deliverable from the post-incident phase. It documents the complete incident timeline, detection methods, response actions taken, root cause analysis, impact assessment, and specific recommendations for improving future prevention and response.",
      "link": "incident-response.html"
    },
    {
      "id": 119,
      "domain": 3,
      "objective": "3.1",
      "difficulty": "medium",
      "question": "What type of exercise tests an organization's incident response plan by walking through a hypothetical scenario without actually deploying resources?",
      "options": [
        "Penetration test",
        "Tabletop exercise",
        "Red team engagement",
        "Vulnerability scan"
      ],
      "correct": 1,
      "explanation": "A tabletop exercise is a discussion-based exercise where key stakeholders walk through a hypothetical incident scenario, discussing their roles, decision points, and response actions. It tests the IR plan and identifies gaps without the cost and disruption of a full-scale simulation.",
      "link": "incident-response.html"
    },
    {
      "id": 120,
      "domain": 3,
      "objective": "3.4",
      "difficulty": "easy",
      "question": "What type of malware analysis can be performed without executing the malicious code?",
      "options": [
        "Dynamic analysis",
        "Static analysis",
        "Runtime analysis",
        "Behavioral analysis"
      ],
      "correct": 1,
      "explanation": "Static analysis examines malware without executing it. Techniques include examining file headers, extracting strings, reviewing imported functions/APIs, disassembling code, and checking file hashes against threat intelligence databases. It is safer than dynamic analysis as the malware is never run.",
      "link": "incident-response.html"
    },
    {
      "id": 121,
      "domain": 3,
      "objective": "3.3",
      "difficulty": "medium",
      "question": "Why should a write blocker be used when performing forensic analysis on a hard drive?",
      "options": [
        "To speed up the data copying process",
        "To prevent any writes to the original evidence drive, preserving its integrity",
        "To encrypt the data during analysis",
        "To convert the file system for compatibility"
      ],
      "correct": 1,
      "explanation": "A write blocker prevents any write operations to the original evidence drive during forensic acquisition and analysis. This ensures the original evidence is not modified, maintaining its forensic integrity and admissibility. Even mounting a drive normally can modify timestamps and metadata.",
      "link": "incident-response.html"
    },
    {
      "id": 122,
      "domain": 3,
      "objective": "3.6",
      "difficulty": "hard",
      "question": "An organization's phishing playbook instructs analysts to check the email headers, extract URLs, query threat intelligence, and check if the user clicked any links. Which of these should be done FIRST to assess immediate impact?",
      "options": [
        "Check email headers for SPF/DKIM results",
        "Determine if the user clicked any malicious links or submitted credentials, as this indicates active compromise requiring immediate containment",
        "Extract URLs for threat intelligence lookup",
        "Report the phishing email to the email provider"
      ],
      "correct": 1,
      "explanation": "The highest priority is determining if the user interacted with the phishing content (clicked links, opened attachments, submitted credentials). If credentials were compromised or malware was downloaded, immediate containment actions (password reset, host isolation) are needed. Header analysis and URL intelligence are important but secondary to assessing immediate impact.",
      "link": "incident-response.html"
    },
    {
      "id": 123,
      "domain": 3,
      "objective": "3.5",
      "difficulty": "medium",
      "question": "Which of the following is an Indicator of Attack (IoA) rather than an Indicator of Compromise (IoC)?",
      "options": [
        "A known malicious file hash found on disk",
        "A process attempting to disable Windows Defender followed by executing an encoded PowerShell command",
        "A malicious IP address found in firewall logs",
        "A suspicious domain in DNS query logs"
      ],
      "correct": 1,
      "explanation": "Indicators of Attack (IoAs) describe adversary behavior patterns in real-time (e.g., disabling security tools then executing encoded commands), while Indicators of Compromise (IoCs) are static artifacts left behind (file hashes, IP addresses, domain names). IoAs focus on what the attacker is doing, IoCs focus on evidence they were there.",
      "link": "incident-response.html"
    },
    {
      "id": 124,
      "domain": 3,
      "objective": "3.2",
      "difficulty": "hard",
      "question": "During recovery from a ransomware incident, the team plans to restore from backups. What must be verified BEFORE restoring backups to production?",
      "options": [
        "That the backup vendor's contract is current",
        "That the backups are not infected, the attack vector has been closed, and the restored systems are patched and hardened before reconnecting to the network",
        "That users are notified about the downtime",
        "That the insurance claim has been filed"
      ],
      "correct": 1,
      "explanation": "Before restoring from backups: (1) verify backups are clean and not infected with the same ransomware, (2) ensure the attack vector has been identified and closed, (3) patch the vulnerability that was exploited, and (4) harden systems before reconnecting them. Restoring without these steps risks immediate re-infection.",
      "link": "incident-response.html"
    },
    {
      "id": 125,
      "domain": 3,
      "objective": "3.7",
      "difficulty": "easy",
      "question": "Which team within an organization is typically responsible for coordinating the response to a security incident?",
      "options": [
        "The marketing department",
        "The Computer Security Incident Response Team (CSIRT) or Security Operations Center (SOC)",
        "The accounting department",
        "The facilities management team"
      ],
      "correct": 1,
      "explanation": "The CSIRT (Computer Security Incident Response Team) or SOC (Security Operations Center) is responsible for coordinating incident response. The CSIRT typically includes security analysts, forensic investigators, and management, with support from IT, legal, HR, and communications as needed.",
      "link": "incident-response.html"
    },
    {
      "id": 126,
      "domain": 4,
      "objective": "4.1",
      "difficulty": "easy",
      "question": "What is the primary purpose of a vulnerability assessment report?",
      "options": [
        "To track employee performance metrics",
        "To communicate identified vulnerabilities, their severity, and recommended remediation actions to stakeholders",
        "To document network bandwidth usage",
        "To list all software licenses in the organization"
      ],
      "correct": 1,
      "explanation": "A vulnerability assessment report communicates the findings from vulnerability scans and assessments, including identified vulnerabilities, their severity ratings, affected systems, potential business impact, and prioritized remediation recommendations for technical and management stakeholders.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 127,
      "domain": 4,
      "objective": "4.2",
      "difficulty": "easy",
      "question": "When writing an executive summary for a security report, what is the MOST important consideration?",
      "options": [
        "Including as many technical details as possible",
        "Using clear, non-technical language that communicates business risk and recommended actions",
        "Making the summary longer than the full report",
        "Including raw log data for reference"
      ],
      "correct": 1,
      "explanation": "Executive summaries must use clear, non-technical language that conveys business risk, key findings, and recommended actions. Executives need to understand the business impact and make decisions, not parse technical details. The full technical details belong in the body of the report for technical teams.",
      "link": "start-here.html"
    },
    {
      "id": 128,
      "domain": 4,
      "objective": "4.3",
      "difficulty": "medium",
      "question": "When communicating risk to senior management, which approach is MOST effective?",
      "options": [
        "Presenting a list of all CVE numbers found in the environment",
        "Translating technical vulnerabilities into business risk terms including potential financial impact, regulatory consequences, and reputational damage",
        "Showing raw SIEM logs",
        "Providing the full CVSS vector strings for each vulnerability"
      ],
      "correct": 1,
      "explanation": "Senior management understands business risk, not technical jargon. Effective risk communication translates vulnerabilities into business terms: potential revenue loss, regulatory fines, operational disruption, and reputational damage. This enables informed decision-making about resource allocation for remediation.",
      "link": "start-here.html"
    },
    {
      "id": 129,
      "domain": 4,
      "objective": "4.4",
      "difficulty": "medium",
      "question": "Which KPI (Key Performance Indicator) BEST measures the effectiveness of a vulnerability management program?",
      "options": [
        "Total number of scans performed per month",
        "Mean time to remediate (MTTR) critical and high vulnerabilities",
        "Number of security tools purchased",
        "Total number of emails sent by the security team"
      ],
      "correct": 1,
      "explanation": "MTTR for critical and high vulnerabilities directly measures how quickly the organization addresses its most significant risks. Other useful KPIs include scan coverage percentage, patch compliance rate, and aging of open vulnerabilities. Total scans performed measures activity, not effectiveness.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 130,
      "domain": 4,
      "objective": "4.5",
      "difficulty": "easy",
      "question": "Which regulatory standard requires regular vulnerability scanning for organizations that process credit card payments?",
      "options": [
        "HIPAA",
        "PCI DSS",
        "FERPA",
        "SOX"
      ],
      "correct": 1,
      "explanation": "PCI DSS (Payment Card Industry Data Security Standard) requires organizations processing credit card data to perform regular vulnerability scans, including quarterly external scans by an Approved Scanning Vendor (ASV) and internal scans after significant changes. Requirement 11.3 specifically addresses vulnerability scanning.",
      "link": "nist-framework.html"
    },
    {
      "id": 131,
      "domain": 4,
      "objective": "4.6",
      "difficulty": "medium",
      "question": "What should a security dashboard prioritize displaying for SOC analysts?",
      "options": [
        "Company stock prices and financial data",
        "Real-time alert counts by severity, open incidents, mean time to respond, and trending threat indicators",
        "Employee vacation schedules",
        "Historical budget allocations"
      ],
      "correct": 1,
      "explanation": "An effective SOC dashboard displays operational metrics: real-time alert volume by severity, open/in-progress incidents, MTTR, trending threat indicators, scan coverage, and SLA compliance. This gives analysts situational awareness and helps managers allocate resources effectively.",
      "link": "start-here.html"
    },
    {
      "id": 132,
      "domain": 4,
      "objective": "4.7",
      "difficulty": "medium",
      "question": "When presenting vulnerability findings to a development team, which format is MOST actionable?",
      "options": [
        "A PDF report with executive-level summaries only",
        "Specific vulnerabilities mapped to affected code components with remediation guidance and code examples",
        "A verbal summary in a team meeting with no written documentation",
        "A list of CVSS scores without context"
      ],
      "correct": 1,
      "explanation": "Developers need actionable, specific information: which code components are affected, what the vulnerability is, how to fix it (with code examples where possible), and the severity. Mapping vulnerabilities to specific components and providing remediation guidance enables developers to prioritize and fix issues efficiently.",
      "link": "owasp-top10.html"
    },
    {
      "id": 133,
      "domain": 4,
      "objective": "4.8",
      "difficulty": "easy",
      "question": "What is remediation tracking in vulnerability management?",
      "options": [
        "Tracking the performance of the security team",
        "Monitoring the progress of vulnerability fixes from identification through verification of successful remediation",
        "Tracking the cost of security tools",
        "Recording the number of incidents per month"
      ],
      "correct": 1,
      "explanation": "Remediation tracking monitors the lifecycle of each vulnerability from discovery through remediation and verification. It tracks which vulnerabilities have been assigned, their remediation status, whether they are within SLA, and confirms through rescanning that fixes were effective.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 134,
      "domain": 4,
      "objective": "4.1",
      "difficulty": "medium",
      "question": "A vulnerability report shows 2,500 findings. How should the analyst BEST organize this report for different audiences?",
      "options": [
        "Present all 2,500 findings in a single list sorted alphabetically",
        "Create a layered report: executive summary with risk overview, management section with trends and SLA metrics, and technical appendix with full finding details grouped by asset criticality",
        "Only report the top 10 findings and discard the rest",
        "Send the raw scanner output to all stakeholders"
      ],
      "correct": 1,
      "explanation": "A layered report structure serves different audiences: executives get a risk-focused summary with key metrics, management gets trending data and SLA compliance information, and technical teams get detailed findings organized by asset criticality or business unit. This approach ensures each audience receives appropriate information for their decision-making needs.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 135,
      "domain": 4,
      "objective": "4.4",
      "difficulty": "medium",
      "question": "Which metric measures the percentage of organizational assets that are included in regular vulnerability scans?",
      "options": [
        "Mean Time to Detect",
        "Scan coverage rate",
        "False positive rate",
        "Incident count"
      ],
      "correct": 1,
      "explanation": "Scan coverage rate measures the percentage of known assets that are regularly scanned for vulnerabilities. Low coverage means unscanned assets may harbor unknown vulnerabilities. Organizations should aim for near-100% coverage across all asset types (servers, workstations, network devices, cloud resources).",
      "link": "cvss-calculator.html"
    },
    {
      "id": 136,
      "domain": 4,
      "objective": "4.5",
      "difficulty": "hard",
      "question": "An organization must demonstrate compliance with both PCI DSS and HIPAA. How should vulnerability management reporting address both frameworks?",
      "options": [
        "Create separate vulnerability management programs for each regulation",
        "Map vulnerability management activities to both frameworks' requirements in a unified reporting structure, identifying overlapping and unique requirements",
        "Ignore HIPAA and focus only on PCI DSS since it is more specific",
        "Only report vulnerabilities that are mentioned in both frameworks"
      ],
      "correct": 1,
      "explanation": "A unified reporting approach maps vulnerability management activities to both frameworks' requirements, identifying overlaps (both require regular scanning and patching) and unique requirements (PCI DSS requires quarterly ASV scans; HIPAA requires risk analysis). This avoids duplicate effort while ensuring full compliance with both.",
      "link": "nist-framework.html"
    },
    {
      "id": 137,
      "domain": 4,
      "objective": "4.3",
      "difficulty": "easy",
      "question": "What is the purpose of a risk register?",
      "options": [
        "To register new employees in the security team",
        "To document identified risks, their severity, owners, mitigation status, and target remediation dates",
        "To register security tools and their license keys",
        "To log daily attendance"
      ],
      "correct": 1,
      "explanation": "A risk register is a centralized document that records all identified risks, their assessment (likelihood and impact), risk owners, current mitigation status, compensating controls, and target remediation dates. It provides a comprehensive view of organizational risk for management decision-making.",
      "link": "nist-framework.html"
    },
    {
      "id": 138,
      "domain": 4,
      "objective": "4.6",
      "difficulty": "hard",
      "question": "A CISO requests a dashboard showing vulnerability management program maturity. Which combination of metrics would BEST demonstrate maturity?",
      "options": [
        "Total budget spent on security tools",
        "MTTR trending down over time, scan coverage increasing, SLA compliance rate improving, and reduction in recurring vulnerabilities",
        "Number of security certifications held by staff",
        "Count of security policies documented"
      ],
      "correct": 1,
      "explanation": "Program maturity is demonstrated by improving trends: decreasing MTTR shows faster remediation, increasing scan coverage shows expanding visibility, improving SLA compliance shows process adherence, and decreasing recurring vulnerabilities shows that root causes are being addressed. These metrics together demonstrate continuous improvement.",
      "link": "start-here.html"
    },
    {
      "id": 139,
      "domain": 4,
      "objective": "4.2",
      "difficulty": "medium",
      "question": "An executive summary for an incident report should include which of the following?",
      "options": [
        "Complete packet captures and memory dumps",
        "A brief description of the incident, business impact, actions taken, current status, and recommended next steps",
        "All SIEM alert details in chronological order",
        "A full technical root cause analysis with code-level details"
      ],
      "correct": 1,
      "explanation": "An executive summary should concisely cover: what happened (incident description), the business impact (systems affected, data compromised), what was done (response actions), current status (contained, eradicated, recovering), and recommended next steps. Technical details belong in the full report body.",
      "link": "incident-response.html"
    },
    {
      "id": 140,
      "domain": 4,
      "objective": "4.7",
      "difficulty": "easy",
      "question": "Why is it important to tailor security communications to the audience?",
      "options": [
        "To make the communication longer",
        "Because different stakeholders have different levels of technical knowledge and need information relevant to their decision-making responsibilities",
        "To hide information from certain groups",
        "To reduce the amount of work for the security team"
      ],
      "correct": 1,
      "explanation": "Different stakeholders need different levels of detail: executives need business risk and impact, managers need operational metrics and resource needs, and technical teams need specific findings and remediation steps. Tailoring ensures each audience can understand and act on the information appropriately.",
      "link": "start-here.html"
    },
    {
      "id": 141,
      "domain": 4,
      "objective": "4.4",
      "difficulty": "hard",
      "question": "An organization tracks these vulnerability management metrics: total open vulnerabilities, MTTR by severity, SLA compliance rate, and scan coverage. The MTTR for Critical vulnerabilities increased from 5 days to 15 days this quarter. What does this trend MOST likely indicate?",
      "options": [
        "The security program is improving",
        "There may be resource constraints, process bottlenecks, or increased vulnerability volume overwhelming the remediation capacity",
        "The scanning tools are becoming more accurate",
        "Fewer vulnerabilities are being discovered"
      ],
      "correct": 1,
      "explanation": "Increasing MTTR for Critical vulnerabilities indicates the organization is taking longer to remediate its most serious risks. This could be caused by insufficient staffing, process bottlenecks (change management delays, testing constraints), increased vulnerability volume, or growing technical debt. This trend requires investigation and corrective action.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 142,
      "domain": 4,
      "objective": "4.8",
      "difficulty": "medium",
      "question": "How should remediation progress be verified after patches are applied?",
      "options": [
        "Trust that the patch was applied correctly based on the technician's confirmation",
        "Perform a follow-up vulnerability scan to verify the vulnerability is no longer detected on the remediated systems",
        "Wait for the next scheduled quarterly scan",
        "Check only that the system rebooted successfully"
      ],
      "correct": 1,
      "explanation": "Remediation should be verified through follow-up scanning (rescanning) to confirm the vulnerability is no longer present. A successful patch installation does not always mean the vulnerability is fully mitigated. Verification scanning confirms the fix was effective and closes the remediation ticket with evidence.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 143,
      "domain": 4,
      "objective": "4.3",
      "difficulty": "medium",
      "question": "When communicating a newly discovered critical vulnerability to the IT operations team, which information is MOST essential to include?",
      "options": [
        "The complete history of the CVE and its discoverer",
        "Affected systems, exploitability status, recommended remediation actions, and the deadline for patching",
        "The CVSS vector string only",
        "A link to the vendor's blog post"
      ],
      "correct": 1,
      "explanation": "IT operations needs actionable information: which specific systems are affected, whether the vulnerability is being actively exploited (urgency level), what patches or workarounds to apply, and the SLA deadline for remediation. This enables them to plan and execute remediation efficiently.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 144,
      "domain": 4,
      "objective": "4.5",
      "difficulty": "medium",
      "question": "Which compliance framework provides a voluntary set of cybersecurity guidelines organized around five functions: Identify, Protect, Detect, Respond, and Recover?",
      "options": [
        "PCI DSS",
        "NIST Cybersecurity Framework (CSF)",
        "ISO 27001",
        "COBIT"
      ],
      "correct": 1,
      "explanation": "The NIST Cybersecurity Framework (CSF) organizes cybersecurity activities into five core functions: Identify, Protect, Detect, Respond, and Recover. It is voluntary (except for federal agencies) and provides a flexible, risk-based approach that organizations of any size can adopt and reference in reporting.",
      "link": "nist-framework.html"
    },
    {
      "id": 145,
      "domain": 4,
      "objective": "4.1",
      "difficulty": "medium",
      "question": "What is the benefit of including trend analysis in vulnerability reports?",
      "options": [
        "It makes the report appear more professional",
        "It shows whether the organization's security posture is improving, stable, or declining over time, enabling data-driven decisions",
        "It reduces the number of pages in the report",
        "It eliminates the need for executive summaries"
      ],
      "correct": 1,
      "explanation": "Trend analysis reveals whether vulnerability counts are increasing or decreasing, whether MTTR is improving, whether new vulnerability types are emerging, and whether remediation efforts are keeping pace with discovery. This enables management to make data-driven decisions about resource allocation and process improvements.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 146,
      "domain": 4,
      "objective": "4.6",
      "difficulty": "easy",
      "question": "What type of visualization is MOST effective for showing vulnerability distribution across severity levels?",
      "options": [
        "A spreadsheet with raw numbers",
        "A bar chart or pie chart showing the count or percentage of vulnerabilities by severity (Critical, High, Medium, Low)",
        "A paragraph of text describing each vulnerability",
        "A network diagram"
      ],
      "correct": 1,
      "explanation": "Bar charts and pie charts effectively communicate the distribution of vulnerabilities across severity levels at a glance. They allow stakeholders to quickly see the proportion of Critical vs. High vs. Medium vs. Low findings and track how the distribution changes over time.",
      "link": "start-here.html"
    },
    {
      "id": 147,
      "domain": 4,
      "objective": "4.7",
      "difficulty": "hard",
      "question": "A security team discovers a critical zero-day vulnerability affecting the organization's primary customer-facing application. Multiple stakeholders need to be notified. What is the correct notification priority order?",
      "options": [
        "Media first, then customers, then internal teams",
        "Incident response team and CISO first, then IT operations for immediate mitigation, then executive leadership, then legal/PR for external communication planning",
        "All employees via company-wide email, then management",
        "Customers first, then regulatory bodies, then internal teams"
      ],
      "correct": 1,
      "explanation": "The correct priority is: (1) IR team and CISO for immediate assessment and decision-making, (2) IT operations to implement mitigations, (3) executive leadership for strategic decisions, (4) legal and PR to prepare for any external communications. Premature external notification without a mitigation plan can increase risk.",
      "link": "incident-response.html"
    },
    {
      "id": 148,
      "domain": 4,
      "objective": "4.8",
      "difficulty": "medium",
      "question": "What is the purpose of a vulnerability management SLA compliance report?",
      "options": [
        "To track the number of security tools deployed",
        "To measure whether vulnerabilities are being remediated within the agreed-upon timeframes for each severity level",
        "To count the number of security incidents",
        "To list all vendors used by the organization"
      ],
      "correct": 1,
      "explanation": "An SLA compliance report tracks whether vulnerabilities are being remediated within the organization's defined timeframes for each severity level (e.g., Critical within 15 days, High within 30 days). It identifies teams or systems that consistently miss SLAs and helps management address systemic remediation obstacles.",
      "link": "cvss-calculator.html"
    },
    {
      "id": 149,
      "domain": 4,
      "objective": "4.2",
      "difficulty": "hard",
      "question": "When writing a technical incident report, the analyst should include which level of detail about the attack methodology?",
      "options": [
        "Only state that an incident occurred without details",
        "Detailed attack chain documentation including initial access vector, tools used, lateral movement paths, data accessed, and IoCs mapped to MITRE ATT&CK techniques",
        "Only the final impact without the attack path",
        "A single sentence summary"
      ],
      "correct": 1,
      "explanation": "A technical incident report should document the complete attack chain: how the attacker gained initial access, what tools/techniques they used (mapped to MITRE ATT&CK for consistency), how they moved laterally, what data they accessed or exfiltrated, all identified IoCs, and the timeline. This detail enables defenders to close gaps and detect similar attacks.",
      "link": "incident-response.html"
    },
    {
      "id": 150,
      "domain": 4,
      "objective": "4.3",
      "difficulty": "hard",
      "question": "The board of directors requests a quarterly security posture briefing. Which metrics and format would be MOST appropriate?",
      "options": [
        "A 50-page technical report with all CVE details",
        "A concise presentation showing risk trends (improving/declining), key incidents and their business impact, compliance status, benchmarking against industry peers, and top investment recommendations",
        "A live demo of the SIEM console",
        "Individual vulnerability tickets printed on paper"
      ],
      "correct": 1,
      "explanation": "Board-level reporting should be concise, visual, and business-focused: risk posture trends over time, significant incidents and their business impact, compliance status with relevant regulations, industry benchmarking, and prioritized recommendations for security investments. The goal is to enable governance decisions, not to convey technical details.",
      "link": "nist-framework.html"
    }
  ]
}